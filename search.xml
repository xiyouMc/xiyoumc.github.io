<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[爬虫入门：Firefox 结合 ScrapyShell 爬取网页数据]]></title>
    <url>%2F2017%2F11%2F09%2FScrapyShell%2F</url>
    <content type="text"><![CDATA[阅读本篇大概需要 4 分钟。 本来这篇是要接着之前 Python 基础的，但由于基础讲的太多，真的会很累。所以先暂停一两篇关于 Python 基础的分享。这篇分享一些有意思的东西。 今天我在 Github 上创建了一个组织，名叫「SpiderMan」 这个组织的目的是玩转 Python 爬虫，目前其中有一个项目就是昨天我提到的 “什么值得买” 这个平台的爬虫。 目前有三个读者联系到我了，我初步了解了下有一个是爬虫高手 A，另外两个 B 和 C 是有一定 Python 基础，但在爬虫方面还是初次。不过我对他们都是同样的看待，我们建了一个微信群他们有问题都会抛出来。其次我也会去主动问他们某个知识点是否了解，比如今天要提到的 Scrapy Shell。除了刚才提到的 A 会， B 和 C 对这个只是听到过。所以我就把这个知识点在这里安利下。（当然，有兴趣加入组织的可以在后台或者 Github Issues 里面联系我） Scrapy Shell 是什么？ 你可以把这个理解为 Python 爬虫的一个测试工具。提到爬虫，我们最常见就是提取 HTML 中某个标签下的数据，但在提取之前我们需要找到这个标签位置，这个位置在学术上就是 XPath。 大家都知道 HTML 的页面是 XML 格式的，在 XML 中需要定位到某个标签的话就需要有个路径。所以你就可以把 XPath 理解为 XML 中某个标签的路径，比如从 html 标签到 a 标签的内容。 举个实际的简单例子，我们来找找 “什么值得买” 官网页面的 Logo 所在的 Xpath 路径： 1.在 FireFox 中打开“什么值得买”的官网 2.在当前页面点击鼠标右键，并选中 “查看元素” 3.选中之后，会展示如下界面，然后选中工具栏的左上角 箭头按钮，选中之后就可以用鼠标点击页面上的任意内容，比如我这里点击 Logo 看到图片最底部会出现一个路径，这就是 Logo 在 xml 中的路径。可以看到 html-&gt;body……-&gt; img 就是 这个 Logo 的 XPath。其中每个路径主要分为三段，第一段是标签名，第二段 # 后面的是当前标签的 id ，第三段 . 后面的是标签的 class 名。那么这个 XPath 就可以这么写： 有了这个 Xpath，我们就可以通过写 Python 的代码去拿到这个标签的数据，一般我们会用到 Scrapy 框架来做这件事。这篇文章暂不分享 Scrapy 框架，不了解的可以看 用 Scrapy 从零写一个爬虫。 那么，我们如何在不写代码的情况下去校验这段 XPath 是否能拿到标签数据呢？ 这时候我们就需要用到 Scrapy Shell 来测试这个 XPath 路径到底能不能拿到这个 Logo 图片的地址。 命令: 1scrapy shell &apos;url 地址&apos; 1➜ /Users/xiyouMc &gt; scrapy shell &apos;https://www.smzdm.com&apos;&gt;&gt;&gt; response.xpath(&apos;/html/body/header[@id=&quot;header&quot;]/div[@id=&quot;global-search&quot;]/div[@class=&quot;search-inner z-clearfix&quot;]/h1[@id=&quot;logo&quot;]/a/img/@src&apos;)[&lt;Selector xpath=&apos;/html/body/header[@id=&quot;header&quot;]/div[@id=&quot;global-search&quot;]/div[@class=&quot;search-inner z-clearfix&quot;]/h1[@id=&quot;logo&quot;]/a/img/@src&apos; data=u&apos;https://res.smzdm.com/pc/v1.0/dist/img/a&apos;&gt;] (看不清的，可以在浏览器打开) 然后我们通过 reponse.xpath() 来拿到这个路径下的标签数据。不过这时候拿到的还是一个 Selector 对象,要拿到准确的数据我们在后面加上 extract() 1&gt;&gt;&gt; response.xpath(&apos;/html/body/header[@id=&quot;header&quot;]/div[@id=&quot;global-search&quot;]/div[@class=&quot;search-inner z-clearfix&quot;]/h1[@id=&quot;logo&quot;]/a/img/@src&apos;).extract()[u&apos;https://res.smzdm.com/pc/v1.0/dist/img/activity/17double11/double11gif.gif&apos;]&gt;&gt;&gt; 这样我们就通过Scrapy Shell 来拿到了 XPath 的标签数据。当然，这只是爬虫的第一步，不过这也算是爬虫中最关键的一步。 预告下，下周我可能会在某天晚上直播一场从零开始的一个爬虫项目，敬请期待。 有兴趣加入这个组织的可以加我微信 ‘mcx1469’ ，也可以在我的 Github 仓库的 Issues 中提一些，地址: https://github.com/xiyouMc/SmzdmSpider]]></content>
      <categories>
        <category>技术</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[用 Scrapy 从零写一个爬虫]]></title>
    <url>%2F2017%2F07%2F13%2FScrapy%20Using%2F</url>
    <content type="text"><![CDATA[开头这两天后台收到了很多读者发消息说：“看了之前写的关于爬虫的文章之后，自己也想写一个爬虫但不知从何下手”。那么我今天就分享一个简单的案例，和大家一起从零写一个简单的爬虫。 在开始分享之前，我想提一件事情。 我知道，爬虫其实在部分外行人心目中一直是一个低劣或者低俗的人才做的事。那么，不管你是不是这么想，我只能说一句：要是没有爬虫我相信很多公司根本就没法起来。 那么，今天我主要通过一个爬虫框架 Scrapy 来一步步实现爬取 V2EX 首页所有的热门文章，旨在让你掌握这个框架来爬取对自己有用的数据。 正文 一、Scrapy 是什么？官网：http://scrapy-chs.readthedocs.io/zh_CN/latest/intro/overview.html Scrapy是一个为了爬取网站数据，提取结构性数据而编写的应用框架。可以应用到数据挖掘，信息处理或存储历史数据等一系列的程序中。 其最初是为了页面爬取（更确切的来说，网络爬取）所设计的，也可以应用在获取API所返回的数据或者通用的网络爬虫。 Scrapy是一个非常强大且好用的爬虫框架，它不仅提供了一些开箱即用的基础组件，还提供了强大的自定义功能。 框架的学习就是修改配置文件，填充代码就可以了。 二、安装 Scrapy？由于我是用 Mac 来开发的，所以安装命令也是 Mac 下的，至于 Window 和 Linux 可以参考安装。 pip install scrapy 当然，一开始你得有 Python 的开发环境，这里就不安利 Python 的安装方法了。直接百度即可。 三、用 Scrapy 创建一个项目Scrapy 中提供了 startproject 命令来创建爬虫项目。命令如下： scrapy startproject V2EX 我们创建一个项目 V2EX 用来爬取 V2 首页文章的所有信息。其中： spiders 文件夹下就是你要实现爬虫功能的核心代码。在 spiders 文件夹下创建一个 spider ，用来爬取 V2 首页文章。 scrapy.cfg 是项目的配置文件。 settings.py用于设置请求的参数，使用代理，爬虫数据后文件保存等等的。 四、Scrapy 爬取 V2 首页文章1、新建 v2exSpider 在 spiders 文件夹下新建一个文件， v2exSpider.py 如上图，start_urls 中添加 v2ex 的首页地址，同时重写 parse 方法。这样 Spider 将基于 start_urls 中的地址进行访问，并将数据回调给 parse 方法。 其中，response 就是返回的网页数据。 处理好的数据放在 items 中，在 items.py 设置好要处理哪些数据字段。这里我们来抓取 V2 首页的：作者地址、作者头像、文章地址、所属节点、作者昵称、最后一次回复者昵称、最后一次回复者地址、最后一次回复时间。 那么，要解析处理哪些数据在 items.py 中定义好，也就相当于 java 中的实体类: 2、 分析 V2EX 首页各元素的 xpath xpath 的概念可以在 60行代码拿到10G国外xx视频… 中了解，当然你可以直接看这个教程： http://www.w3school.com.cn/xpath/index.asp 通过 Chrome 打开 v2ex.com ，同时在当前页面空白处点击右键，选中 inspect ，这样就可以看到当前页面的 Elements 。（图片略大，耐心访问） 在这里我们可以分析出来每一篇文章的标题、地址等等的 xpath 路径。 同时，发现首页的50篇文章都是属于 div[@class=’cell item’] 的数据，因此我们可以通过selector.xpath(‘//div[@class=”cell item”]’)拿到所有文章的数据，然后再分析出具体数据的 xpath ，从而拿到了所有需要的数据。 解析的数据保存： 这时数据分析处理好了，还有最重要的一步，提交： yield v2Item OK！ 万事俱备，数据保存在哪里，什么格式？ 在 settings.py 中加入两行代码: 如何运行这个爬虫？scrapy crawl v2exSpider 这样就可以把 V2EX 的首页文章信息都爬取到了本地的 csv 文件中了。 最后，你会发现当前代码只能爬取 V2 中首页的文章，这时候你就需要分析到 v2ex 中下一页的 xpath ，然后拿到这个 url ，通过 yield Request(next_link,callback=self.parse)，这样就可以一直爬取到 v2 最后一页的数据。来看看数据： 总结爬虫需谨慎，爬虫需有度。本篇文章中项目的源代码托管在 Github，点击 【阅读原文】 。….end… 行为艺术要持之以恒，iOS专用赞赏通道。 长摁‘识别二维码’，一起进步 生活不止眼前的苟且，还有手下的代码、和嘴上的扯淡——个人博客: http://xiyoumc.0x2048.comGithub:https://www.github.com/xiyouMc 来自公众号 : DeveloperPython]]></content>
      <categories>
        <category>技术</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[别怪罪于 GIL ，那是你没用好而已]]></title>
    <url>%2F2017%2F07%2F05%2FPython_GIL_%E6%B2%A1%E9%82%A3%E4%B9%88%E5%9D%8F%2F</url>
    <content type="text"><![CDATA[我相信你已经听说过 Python 中的全局解释器锁 GIL 。不过，就算你没听说过，我还是会给你安利一遍。 GIL 是啥子东西先声明下 GIL 其实并不是 Python 语言的特性，它其实是在实现 Python 解释器(CPython)时所引入的一个概念。 那么，CPython 又是什么呢？ 类比 C++，这是一套语言的标准，但是可以再不同的编译器上来编译成可执行代码。比较有名的编译器例如 GCC, Visual C++等。Python 也一样，相同的代码可以通过 CPython、PyPy、Psyco、JPython等不同的 Python 环境来执行。比如 JPython 就没有 GIL。 因为 CPython 是大部分环境下默认的 Python 执行环境，所以很多人在概念上就默认 CPython 就是 Python，也就想当然的把 GIL 作为了 Python 语言的缺陷。所以我这里再次明确一点： GIL 并不是 Python 的特性， Python 完全可以不依赖于 GIL。 那么 CPython 中的 GIL 又是什么呢？ 全称是 Global Interpreter Lock。 官网是这么解释的： 一个防止多线程并发执行机器码的一个 Mutex。 尼玛啊，这不就是一个 Bug 般存在的全局锁嘛！表急。。。 真是 Bug ？玩过 Python 的，我相信不少都在担心 GIL 在影响多线程程序的执行性能。但，我这次想说你担心的未免太多了。 这并不是 Python 中的 Bug ，它的存在只不过解决了部分问题，并不能解决全部的问题。毕竟人都无完人。 那么，我们应该怎么合理的使用 GIL 呢？在讨论普通的GIL之前，有一点要强调的是GIL只会影响到那些严重依赖CPU的程序（比如计算型的）。 如果你的程序大部分只会涉及到I/O，比如网络交互，那么使用多线程就很合适， 因为它们大部分时间都在等待。实际上，你完全可以放心的创建几千个Python线程， 现代操作系统运行这么多线程没有任何压力，没啥可担心的。 而对于依赖CPU的程序，你需要弄清楚执行的计算的特点。 例如，优化底层算法要比使用多线程运行快得多。 类似的，由于Python是解释执行的，如果你将那些性能瓶颈代码移到一个C语言扩展模块中， 速度也会提升的很快。如果你要操作数组，那么使用NumPy这样的扩展会非常的高效。 最后，你还可以考虑下其他可选实现方案，比如PyPy，它通过一个JIT编译器来优化执行效率 （不过在写这本书的时候它还不能支持Python 3）。 还有一点要注意的是，线程不是专门用来优化性能的。 一个CPU依赖型程序可能会使用线程来管理一个图形用户界面、一个网络连接或其他服务。 这时候，GIL会产生一些问题，因为如果一个线程长期持有GIL的话会导致其他非CPU型线程一直等待。 事实上，一个写的不好的C语言扩展会导致这个问题更加严重， 尽管代码的计算部分会比之前运行的更快些。 说了这么多，现在想说的是我们有两种策略来解决GIL的缺点。 首先，如果你完全工作于Python环境中，你可以使用 multiprocessing 模块来创建一个进程池， 并像协同处理器一样的使用它。例如，假如你有如下的线程代码： 1234567891011# Performs a large calculation (CPU bound)def some_work(args): ... return result# A thread that calls the above functiondef some_thread(): while True: ... r = some_work(args) ... 修改代码，使用进程池： 12345678910111213141516171819# Processing pool (see below for initiazation)pool = None# Performs a large calculation (CPU bound)def some_work(args): ... return result# A thread that calls the above functiondef some_thread(): while True: ... r = pool.apply(some_work, (args)) ...# Initiaze the poolif __name__ == '__main__': import multiprocessing pool = multiprocessing.Pool() 这个通过使用一个技巧利用进程池解决了GIL的问题。 当一个线程想要执行CPU密集型工作时，会将任务发给进程池。 然后进程池会在另外一个进程中启动一个单独的Python解释器来工作。 当线程等待结果的时候会释放GIL。 并且，由于计算任务在单独解释器中执行，那么就不会受限于GIL了。 在一个多核系统上面，你会发现这个技术可以让你很好的利用多CPU的优势。 另外一个解决GIL的策略是使用C扩展编程技术。 主要思想是将计算密集型任务转移给C，跟Python独立，在工作的时候在C代码中释放GIL。 这可以通过在C代码中插入下面这样的特殊宏来完成： 1234567891011#include "Python.h"...PyObject *pyfunc(PyObject *self, PyObject *args) &#123; ... Py_BEGIN_ALLOW_THREADS // Threaded C code ... Py_END_ALLOW_THREADS ...&#125; 如果你使用其他工具访问C语言，比如对于Cython的ctypes库，你不需要做任何事。 例如，ctypes在调用C时会自动释放GIL。 讨论许多程序员在面对线程性能问题的时候，马上就会怪罪GIL，什么都是它的问题。 其实这样子太不厚道也太天真了点。 作为一个真实的例子，在多线程的网络编程中神秘的 stalls 可能是因为其他原因比如一个DNS查找延时，而跟GIL毫无关系。 最后你真的需要先去搞懂你的代码是否真的被GIL影响到。 同时还要明白GIL大部分都应该只关注CPU的处理而不是I/O. 如果你准备使用一个处理器池，注意的是这样做涉及到数据序列化和在不同Python解释器通信。 被执行的操作需要放在一个通过def语句定义的Python函数中，不能是lambda、闭包可调用实例等， 并且函数参数和返回值必须要兼容pickle。 同样，要执行的任务量必须足够大以弥补额外的通信开销。 武功本没有高低之分，只有我们习武之人才有强弱之别 另外一个难点是当混合使用线程和进程池的时候会让你很头疼。 如果你要同时使用两者，最好在程序启动时，创建任何线程之前先创建一个单例的进程池。 然后线程使用同样的进程池来进行它们的计算密集型工作。 C扩展最重要的特征是它们和Python解释器是保持独立的。 也就是说，如果你准备将Python中的任务分配到C中去执行， 你需要确保C代码的操作跟Python保持独立， 这就意味着不要使用Python数据结构以及不要调用Python的C API。 另外一个就是你要确保C扩展所做的工作是足够的，值得你这样做。 也就是说C扩展担负起了大量的计算任务，而不是少数几个计算。 这些解决GIL的方案并不能适用于所有问题。 例如，某些类型的应用程序如果被分解为多个进程处理的话并不能很好的工作， 也不能将它的部分代码改成C语言执行。 对于这些应用程序，你就要自己需求解决方案了 （比如多进程访问共享内存区，多解析器运行于同一个进程等）。 或者，你还可以考虑下其他的解释器实现，比如PyPy。]]></content>
      <categories>
        <category>Python新手引导</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Python新手引导第二篇]]></title>
    <url>%2F2017%2F07%2F05%2Fpython_GIL%2F</url>
    <content type="text"><![CDATA[刚接触 Python 的时候就听到了 GIL 这个词，同时发现这个词经常和 Python 无法高效的实现多线程划上等号。 GIL 是啥子东西先声明下 GIL 其实并不是 Python 语言的特性，它其实是在实现 Python 解释器(CPython)时所引入的一个概念。 那么，CPython 又是什么呢？ 类比 C++，这是一套语言的标准，但是可以再不同的编译器上来编译成可执行代码。比较有名的编译器例如 GCC, Visual C++等。Python 也一样，相同的代码可以通过 CPython、PyPy、Psyco、JPython等不同的 Python 环境来执行。比如 JPython 就没有 GIL。 因为 CPython 是大部分环境下默认的 Python 执行环境，所以很多人在概念上就默认 CPython 就是 Python，也就想当然的把 GIL 作为了 Python 语言的缺陷。所以我这里再次明确一点： GIL 并不是 Python 的特性， Python 完全可以不依赖于 GIL。 那么 CPython 中的 GIL 又是什么呢？ 全称是 Global Interpreter Lock。 官网是这么解释的： 一个防止多线程并发执行机器码的一个 Mutex。 尼玛啊，这不就是一个 Bug 般存在的全局锁嘛！表急。。。 为什么会有 GIL众所周知，CPU 厂商在核心频率上的发展已经被多核心所替代。那么，为了更有效的利用多核处理器的性能，也就出现了多线程的编程方式，随之而来的也即是线程间数据一致性和状态同步的问题。 同样的，Python 也逃不开，为了利用多核 Python 开始支持多线程。而为了解决多线程之间数据完整性和状态同步的最简单、直接的方法自然就是加锁。于是也就有了 GIL 这一把大锁，更可怕的是这种特性被越来越多的代码库开发者接受，并且大量依赖这个特性。 当代码库越来越多的依赖这个特性之后，才发现这是多么的蛋疼和低效。但，当大家开始要去拆分和去除 GIL 的时候，发现大量代码库开发者已经重度依赖 GIL 而且非常难以去除了。 所以，简单的说 GIL 的存在更多的是历史原因。如果非要推倒重来，多线程的问题依然还是要面对的，但是我想，至少会比目前 GIL 这种方式会更加优雅点。 证明 GIL 的低效GIL 无疑就是一把全局排它锁，毫无疑问全局锁的存在会对多线程的效率有不小的影响。甚至可以认为 Python 特么的就是一个单线程的语言。为什么说它是一个单线程，有依据的，更扯淡的是它还有可能会比单线程的效率都差。 来个大众的例子，一个循环 1 亿次的计数器函数，通过一个单线程执行两次和一个多线程同时执行一次。我们来看看耗时： 为了减少线程库本身性能损耗对测试结果带来的影响，这里单线程的代码同样用到了线程，只不过顺序执行两次来模拟单线程。 顺序执行的单线程(single_thread.py) 12345678910111213141516171819202122from threading import Threadimport timedef my_counter(): i = 0 for _ in range(100000000): i = i + 1 return Truedef main(): thread_array = &#123;&#125; start_time = time.time() for tid in range(2): t = Thread(target=my_counter) t.start() t.join() end_time = time.time() print("Total time: &#123;&#125;".format(end_time - start_time))if __name__ == '__main__': main() 同时执行的两个并发线程(multi_thread.py) 1234567891011121314151617181920212223from threading import Threadimport timedef my_counter(): i = 0 for _ in range(100000000): i = i + 1 return Truedef main(): thread_array = &#123;&#125; start_time = time.time() for tid in range(2): t = Thread(target=my_counter) t.start() thread_array[tid] = t for i in range(2): thread_array[i].join() end_time = time.time() print("Total time: &#123;&#125;".format(end_time - start_time))if __name__ == '__main__': main() 测试结果：]]></content>
      <categories>
        <category>Python新手引导</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[西邮成绩 Apk]]></title>
    <url>%2F2017%2F07%2F05%2F%E8%A5%BF%E9%82%AE%E6%88%90%E7%BB%A9%2F</url>
    <content type="text"><![CDATA[本软件支持查询期中、期末、平时成绩，同时支持四六级成绩查询、排名查询。 妈妈再也不用担心我的成绩了。 使用方法： 教务处学号和密码进行登录。 下载链接：西邮成绩 5.2]]></content>
      <categories>
        <category>软件</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[2017上半年个人总结]]></title>
    <url>%2F2017%2F07%2F03%2F2017%E4%B8%8A%E5%8D%8A%E5%B9%B4%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[来自公众号：DeveloperPython 一眨眼，17年已经过了一半。去年年底写了篇16年的总结，同时也对17年有一些计划。 那么，这些计划又完成的怎么样？ 同样的，这次也针对事业和家庭做个总结。 事业1、技术积累 这半年尝试了很多，也收获了不少。 始于增长，重回本心 在年初的时候，致力于公司的数据增长中。 这个工作是以快速战斗而存在的，并做出百分百的付出，从一开始的玩转国外各大社交、视频平台到产生内部可用的数据源。无一不是以快速战斗而进行的。 重回本心 说实话，Android 已经坚持了5年左右，从大学开始就一直在坚持做 Android，因此，有时候做的东西散了，你会发现自己的内心会有点散，在这个技术高速迭代的移动互联网时代，你会害怕自己深爱的东西会一下子更新的不会了。最后，我选择了重回本心，继续做自己深爱的技术和工作。 学习 Python 这半年，重新学习了一门语言 Python ，Python 这门语言其实在我刚接触互联网的时候就有简单的了解，也一直对 Python 都有一种敬仰的态度，敬仰于其灵活、简单、优雅的特性，但是从未深入学习并积累过。 因此，在今年年初的时候决定上手 Python，实话说，学习这门语言的基础并没有花费我太多时间，大概也就花了一两天不到。快速的学习一门新的语言也一直是我对新技术的态度，然后更漫长的是使用新技术，要学好一门语言应该是将这门语言付诸于实际项目中。 在这半年中我抽出自己大部分的闲暇时间投入到 Python 实践中，其中主要包括了为公司产生价值数据、开通个人公众号、开源个人 Python 库、学习优秀的 Python 网络库中。当然，效果是很明显的，自己的第一个 Python 开源库 WebHubBot 也获得不少的反馈，虽说这不是一个很正派的爬虫库，但最重要的还是看你怎么去用，若你处于品德的制高点，那么对这个开源库笑笑就行了。 其次，在我深入学习了 Requests 这个优秀的 Python 网络库之后，我开发并开源了一个 网易云音乐的组件库 NCMBot，其中语法和设计完全是学习 Requests ，也算是对自己的 Python 编程有了一层约束，同样的也获得了不错的反馈。 小程序 这半年我也抽时间玩了一把小程序，虽说小程序是一个新的东西。但其实对我来讲，它就是前端。一直以来前端是一门我特别、特别反感的语言。我可以看懂别人写的前端代码，但一直没有耐心去独自写一个关于前端的程序。 所以，在小程序如火如荼的时候，我决定抽时间去完成这件事情。编写一个属于自己的前端程序（小程序）Github开源社区。在这个开发过程中，让我学到了很多，更重要的是让我收获了很多额外的增长。关于这些积累，我也分享到了小密圈中。 2、技术分享个人公众号，DeveloperPython 在年初的一个下午，突然一个想法闪现在自己的脑海。开通个人公众号。这个想法其实在大学时候就有个老师建议我去做，当时自己已经拥有了个人App，并且声誉也有那么一丢丢。在大四那年加入了学校的 Linux 3+1，当时的导师是国内知名Linux布道师 陈莉君 陈老师。当时我加入实验室的面试简历就是那款应用，面试的时候老师强烈建议我开通个人公众号。但当时幼稚，觉得放到 微信里面就不是自己的应用了，因此自私和自大导致了当时没有去开通。现在想来，真的是有点后悔的。 年初，开通了个人公众号，旨在分享 Python 的学习经验和一些互联网的技术。同时也收到了很不错的反馈。当然我会一直继续下去。 小密圈 很多人应该不知道什么是小密圈，你可以简单的理解为是一款付费的朋友圈。用户付费进入我的圈子后就可以在这个圈子里面交流各种技术，同时可以对我提问题，我都会一一解答。 小密圈，其实在前年都已经推出了，但一直都不被互联网大部分人所知道。今年年初才活跃了起来，我就是这时候才创建了自己的圈子。都说 小密圈是对名人、大V的变现，所以对于草根人员来说分享才是最重要的。 3、充实自己的闲暇时间17年，我合理规划了自己的周末，不再像以前一样大部分时间都去打游戏、娱乐。在这半年的大部分周末我都在写代码，有时候一写就是一天。 在大学的时候，我厌烦于周内的课程，每天都得早起上课。所以那时候，对我来讲最爽的就是假期。寒暑假可能对于大部分学生来讲就是旅游什么的。但，我说实话，在大二之后每一个寒暑假我都在忙于自己的软件，从工具到社交、从社交到盈利。 工作了，有时候真的希望有像那些寒暑假一样的时间，可以有大量的时间来充实自己，干自己的事情。然后，就只剩下周末，所以与其叹气，不如抓住每一个周末去充实自己。 这些时间让我学到了很多，也获得了很多。 家庭 家庭是一个人活在这个世上的依赖，更是我们奋斗的动力。 这半年，家里所有人都健健康康的。老家的屋子也被我爹妈折腾的像个小洋楼。这时候，突然想简单的扯扯自己的过往。 我是农村出身的，老家的样子一直印在我的脑海，高高的门框和门槛，那种木质的老门和铁门栓，小的时候我总喜欢坐在门内侧锁门的木门栓上，然后荡来荡去。 这么一荡，20几年过去了，那个老屋子也已经塌了，不过现在的老家已经改旧翻新，老爸和老妈也为这个家付出了很多，同时也是我一直以来的榜样。 杭州，这半年算是完成了去年目标的一半，具体是什么目标，可以在16年总结中翻到。这半年，我们也都见了家长。一切都很顺利，我也成了过来人。只差再敲定一件事了。 下半年忠于技术，忠于工作，同时补充自己非技术领域的空缺。 就一个字 “干”]]></content>
      <categories>
        <category>总结</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Tar包高优化解析]]></title>
    <url>%2F2017%2F07%2F03%2FTarParse%2F</url>
    <content type="text"><![CDATA[本文将介绍一个针对Tar包解析时的优化方案，旨在优化内存、提高效率。一、首先讲一个tar包的文件结构。（懂得可以绕开此段）tar只是一个归档文件，并不进行压缩。 1234567891011121314151617181920 struct tar_header &#123; char name[100]; char mode[8]; char uid[8]; char gid[8]; char size[12]; char mtime[12]; char chksum[8]; char typeflag; char linkname[100]; char magic[6]; char version[2]; char uname[32]; char gname[32]; char devmajor[8]; char devminor[8]; char prefix[155]; char padding[12]; &#125;; &gt; 以上是Tar中保存文件信息的数据结构，其后跟着的就是文件的内容。 size为文件大小的八进制字节表示，例如文件大小为90个字节，那么这里就是八进制的90，即为132。 其中，文件大小，修改时间，checksum都是存储的对应的八进制字符串，字符串最后一个字符为空格字符 checksum的计算方法为出去checksum字段其他所有的512-8共504个字节的ascii码相加的值再加上256(checksum当作八个空格，即80x20） 文件内容以512字节为一个block进行分割，最后一个block不足部分以0补齐 两个文件的tar包首先存放第一个文件的tar头结构，然后存储文件内容，接着存储第二个文件的tar头结构，然后存储文件内容 所有文件都存储完了以后，最后存放一个全零的tar结构 所有的tar文件大小应该都是512的倍数，一个空文件打包后为5123字节，包括一个tar结构头，一个全零的block存储文件内容，一个全零的tar结构 检测tar文件格式的方法：121、检测magic字段，即在0x101处检查字符串，是否为ustar。有时某些压缩软件将这个字段设置为空。如果magic字段为空，进入第2步。2、计算校验和，按照上面的方法计算校验和，如果校验和正确的话，那么这就是一个tar文件。 注意：在windows下面，不支持uid、uname等，有的甚至不支持magic，这样就比较麻烦了。 二、Java层普遍的“解压”方式&gt; 因为在jdk中提供了 FilterInputStream,因此我们可以通过继承该类，并构造一个TarEntry的模板，在子类中按每512个字节，将一个tar流分成包含N个512字节的TarEntry. 这样我们就可以将一个tar包通过TarInputStream和TarEntry解开到一个map集合中. 三、内存优化的 “解压”方式&gt; 由于每一个TarEntry都是一个固定大小字节的对象，那么我们可不可以直接读取这块内存，而不是将所有都常驻内存呢？ 答案当然是可以的。 为了内存上的优化和效率上的提升，我们可以直接读取指定EntryNam的内存块。 因为一个tar包基本的组成结构就是 entryName-&gt;data。我们可以拿到每一个EntryName和其对应的内存大小、偏移量，在读取的时候直接在TarInputStream中读取相应内存块。 代码如下： 一个简单维护TarEntry偏移量和字节大小的类McTarEntry。 123456789101112131415161718192021222324252627282930313233343536373839public class McTarEntry &#123; private long offset; private int size; private McTarEntry(Builder builder) &#123; offset = builder.offset; size = builder.size; &#125; public long getOffset() &#123; return offset; &#125; public int getSize() &#123; return size; &#125; public static class Builder &#123; private long offset = 0; private int size = 0; public Builder offset(long offset) &#123; this.offset = offset; return this; &#125; public Builder size(int size) &#123; this.size = size; return this; &#125; public H5TarEntry build() &#123; return new McTarEntry(this); &#125; &#125;&#125; 解析Tar包，将每个McTarEntry保存在map 123456789101112131415161718FileInputStream fis = new FileInputStream(tarPath);BufferedInputStream bis = new BufferedInputStream(fis);TarInputStream tis = new TarInputStream(bis);TarEntry te = null;while ((te = tis.getNextEntry()) != null) &#123; String entryName = te.getName(); if (te.isDirectory() || TextUtils.isEmpty(entryName)) &#123; continue; &#125; McTarEntry mcTarEntry = new McTarEntry.Builder().offset(tis.getCurrentOffset()) .size((int) te.getSize()).build(); tarEntryMap.put(entryName, h5TarEntry);&#125;tis.close(); 读取指定entryName的数据块 1234567891011121314151617181920212223242526272829303132333435363738394041424344public synchronized static byte[] get(String appId, String entryName) &#123; try &#123; byte buffer[] = new byte[2048]; int count; ByteArrayOutputStream bos = new ByteArrayOutputStream(); if (!tarEntryMap.containsKey()) &#123; return null; &#125; long offset = tarEntryMap.get(entryName).getOffset(); int entrySize = tarEntryMap.get(entryName).getSize(); FileInputStream fis = new FileInputStream(tarPath); BufferedInputStream bis = new BufferedInputStream(fis); TarInputStream tis = new TarInputStream(bis); H5Log.d(TAG, "entryName" + entryName + " skip offset:" + offset + " size" + entrySize); tis.skip(offset); if (buffer.length &gt; entrySize) &#123; buffer = new byte[entrySize]; &#125; int bufferSize = 0; while ((count = tis.read(buffer)) != -1) &#123; bos.write(buffer, 0, count); bufferSize += count; // 当前buffer加上已经读取的bufferSize如果超过entrySize那么我们就应该重新计算buffer进行最后一次读取。 if ((bufferSize + buffer.length) &gt; entrySize) &#123; buffer = new byte[entrySize % bufferSize]; bufferSize = entrySize - entrySize % bufferSize; &#125; if (buffer.length == entrySize || entrySize == bufferSize) &#123; break; &#125; &#125; tis.close(); byte[] data = bos.toByteArray(); if (data == null) &#123; return null; &#125; H5Log.d(TAG, "entryName:" + entryName); return data; &#125; catch (IOException e) &#123; H5Log.e(TAG, "exception :" + e); &#125; return null; &#125; 这样就可以通过指定的entryName，根据其offset和 size 计算到这个entry在TarStream中固定内存块，从而拿到真正的数据。 总结：两种读取方式的区别： 第一种优点：减少了I/O操作。缺点：耗费了内存。假如一个很大的资源在这个tar中，但是被使用的概率很低，这样耗费了内存从而不值得这么做。 第二种优点：节省了内存，提高了读取效率缺点：增加了I/O操作，Tar资源可能存在被篡改的风险。 Thanks. By MC.]]></content>
      <categories>
        <category>Java</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Python新手引导第二篇]]></title>
    <url>%2F2017%2F07%2F03%2FPython%E6%96%B0%E6%89%8B%E5%BC%95%E5%AF%BC%E7%AC%AC%E4%BA%8C%E7%AF%87%2F</url>
    <content type="text"><![CDATA[Python新手引导 第二篇 你不知道的Python ###阅读本文需要4.66分钟 上一篇进行了简单的Python讲解，包括历史、多版本共存和安装。若有不明白的同学，可尽情在公众号上给我发消息。保证”第一时间”回复. Python解释器 编写、运行第一个Python atom-runner 一、Python解释器 Python代码是以.py为扩展名的文本文件。要执行代码，就需要Python解释器去执行.py文件。 以下将介绍多种Python解释器: A、 CPythonPython官方的解释器是：CPython.这个解释器是用C语言开发的，因此叫CPython。在终端执行 python 启动的就是CPython解释器。 B、 IPythonIpython是基于CPython的交互式解释器。执行 Python的能力和CPtython一样。可以变量自动补全、自动缩进。与CPython不一样的是： CPython使用&gt;&gt;&gt;作为提示符，而IPython使用In[序号]: C、 PypyPypy是Python开发者为了更好的Hack Python创建的项目。 用Python实现的Python D、 JythonJython是运行在Java平台上的Python解释器，可以直接把Python代码编译成Java字节码执行。这个也是我之前在写一个Java项目的时候用到的解释器。 123456&lt;!-- https://mvnrepository.com/artifact/jython/jython --&gt;&lt;dependency&gt; &lt;groupId&gt;jython&lt;/groupId&gt; &lt;artifactId&gt;jython&lt;/artifactId&gt; &lt;version&gt;2.5.2&lt;/version&gt;&lt;/dependency&gt; Java项目引入Jython之后，会将本机Python环境应用到本项目中。在Java和Python相互调用中起到了重要的作用。 二、编写、运行第一个Python程序 当然在终端中，可以直接通过Python来启动CPython并进行编辑并运行，但这样的缺点就是没法保存，再次执行还必须得复制进行。所以在实际的应用场景中，我们使用文本编辑器来编写Python代码。 以下推荐两款文本剪辑器： Atom，免费、可安装多种插件来更高效的编写代码。 NodePad++,免费、在Window上很实用的文本编辑器 编写并运行第一个Python程序 安装好编辑器之后，打开编辑，新建文件，输入: 编辑Python文件后，将其保存为Hello.py并放到自己的开发目录如 ~/Dev 或者 C:/dev 都可以 通过cd 命令定位到文件的目录,并使用python命令来运行 如果当前文件夹没有Hello.py，会报错如下： 三、atom-runner插件 每一门语言的开始，相信大家都会去找到一个适合自己的编辑器，类似SublineText等等的。当然SublineText也可以运行Python，但是我个人比较推荐Atom。 atom-runnerAtom中的开源插件，可用来执行Python脚本。直接在Atom settings-&gt;install 中搜索atom-runner,安装即可 该插件官方文档指明，可支持JavaScript、CoffeeScript、Ruby、Python、Go、Bash 和 PowerShell scripts. 可执行命令 Ctrl+R (Alt+R on Win/Linux)运行当前活动窗口 Ctrl+Shift + R (Alt+Shif+R on Win/Linux)运行在活动窗口的选择文本 Ctrul+Shift+C 杀掉当前正在运行的进程 Escap 关闭正在运行的窗口 运行结果如下 小结本篇阅读完成之后，花上几分钟时间自行编写并运行下Python，熟悉下Python的环境。]]></content>
      <categories>
        <category>Python新手引导</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Python新手引导第二篇]]></title>
    <url>%2F2017%2F07%2F03%2FPython%E6%96%B0%E6%89%8B%E5%BC%95%E5%AF%BC%E7%AC%AC%E4%B8%89%E7%AF%87%2F</url>
    <content type="text"><![CDATA[Python新手引导 第三篇 Python基础 ###阅读本文需要4.66分钟 有其他计算机语言基础的同学，阅读本篇基础部分建议1到2分钟。 基础类型和变量 list 和 tuple 第一、基础类型和变量]]></content>
      <categories>
        <category>Python新手引导</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Python新手引导第二篇]]></title>
    <url>%2F2017%2F07%2F03%2FPython%E6%96%B0%E6%89%8B%E5%BC%95%E5%AF%BC%20%E7%AC%AC%E5%9B%9B%E7%AF%87%2F</url>
    <content type="text"><![CDATA[Python新手引导 第四篇 ###阅读本文需要4.66分钟 之后的引导将以例子入手，作为一个程序员，我相信你从例子入手的话会更快的掌握一门语言。 条件判断、循环、dict和set 函数 列表生成式update order_pay_num set content = ‘支付一次，永久免费使用’第一、条件判断、循环、dict和set 1.1 条件判断12345678#coding:utf-8age = input('input num:')if age &gt; 18: print('age 大于 18')elif age &gt; 11 and age &lt; 18: print('age 大于11 并小于18')else : print('其他') 如下： 12345678if &lt;条件判断1&gt;: &lt;执行1&gt;elif &lt;条件判断2&gt;: &lt;执行2&gt;elif &lt;条件判断3&gt;: &lt;执行3&gt;else: &lt;执行4&gt; 其中input():2.x 下 input读取的内容和输入的一样的。 但在3.x以上 读取的都是字符串，这一点大家要和raw_input()做区分 1.2 循环1.2.1 for in123names = ['Mark','Alison']for name in names: print(name) 1for &lt;元素&gt; in &lt;集合&gt;： 在这里给大家讲一下 range()，rangek可以生成对应参数的n个整数。如： range(100),就会生成0 到 100的整数。因此在遍历list的时候也可以这样： 123names = ['Mark','Alison']for index in range(len(names)): print(names[index]) 1.2.2 while123456sum = 0n = 99while n &gt; 0: sum = sum + n n = n -2print(sum) 1.3 集合1.3.1 dict Python中内置的字典。在其他语言中是 map之类的 (key-value) 1234567891011121314&gt;&gt;&gt; names = &#123;'Mark':'18','Alison':'18'&#125;&gt;&gt;&gt; names&#123;'Alison': '18', 'Mark': '18'&#125;&gt;&gt;&gt; names['Mark']'18'&gt;&gt;&gt; names['Jordan'] = '88'&gt;&gt;&gt; names&#123;'Jordan': '88', 'Alison': '18', 'Mark': '18'&#125;&gt;&gt;&gt; names.get('Ali','-1') #get方法可指定默认值，若这个key不存在，返回默认值'-1'&gt;&gt;&gt; names.pop('Jordan') #Pop出栈'88'&gt;&gt;&gt; names&#123;'Alison': '18', 'Mark': '18'&#125; dict适用于需要高速查找的地方。 1.3.2 set 一组不包含value的 key集合，并且不能重复。入参是 list 123456789&gt;&gt;&gt; a = set([1,2,3])&gt;&gt;&gt; aset([1, 2, 3])&gt;&gt;&gt; a.add(5)&gt;&gt;&gt; aset([1, 2, 3, 5])&gt;&gt;&gt; a.remove(5)&gt;&gt;&gt; aset([1, 2, 3]) 切记关于key的都是不可变的。因为存储的时候，是通过计算key的hash来做的。 第二、函数2.1 内置函数123456789101112&gt;&gt;&gt; abs(1.2) # 求绝对值1.2&gt;&gt;&gt; abs(-1)1&gt;&gt;&gt; int('1') # 将str的转换为int1&gt;&gt;&gt; str(1) # 将int转换为str'1'&gt;&gt;&gt; bool(1) # 转换bool值True&gt;&gt;&gt; bool('')False 2.2 定义函数 Python中使用def定义函数，并可通过 return来返回值 12345678910111213&gt;&gt;&gt; def myAbs(x):... if x &gt; 0:... return x... else:... return -x...&gt;&gt;&gt;&gt;&gt;&gt; myAbs(1)1&gt;&gt;&gt; myAbs(-1)1&gt;&gt;&gt; myAbs(-2)2 其中 return表示函数执行的终止，并将结果返回。需要注意的是 return None可直接用 return表示 2.2.1 空函数12def nop(): pass #可作为占位符，表示还没想好写什么 2.2.2 返回多个值123def fun(): return '1','2'a,b = fun() 这个还是比较方便的。 不用我们再继续封装起来返回，唯一恶心的就是得约定好规则。 其实这返回不是两个值，而是一个tuple，这个得理解下 2.2.3 默认参数12def fun(a,b=2) print a,b 其中b的默认值是2 123def fun(L=[]) L.append('End') return L 传一个list，并添加 End再返回。其中要注意的是，python会记住append的元素。意思就是：如果你多次调用 fun() ，会发现 之后的元素都是 End 因此这种传递List的方式如下： 12345def fun(L=None): if L is None: L = [] L.append('End') return L 2.2.4 可变参数，使用 *1234567nums = [1,2,3]def addNum(*n): sum = 0 for num in n: sum +=num return sumaddNum(*nums) *nums表示把nums这个list的所有元素作为可变参数传进去。这种写法相当有用，而且很常见。 2.2.5 关键字参数 **表示允许传入0个或者任意个含参数名的参数，这些关键字参数在函数内部自动组装为一个dict. 12345678def person(name, age, **kw): print('name:', name, 'age:', age, 'other:', kw)&gt;&gt;&gt; person('Michael', 30)name: Michael age: 30 other: &#123;&#125;&gt;&gt;&gt; person('Bob', 35, city='Beijing')name: Bob age: 35 other: &#123;'city': 'Beijing'&#125;&gt;&gt;&gt; person('Adam', 45, gender='M', job='Engineer')name: Adam age: 45 other: &#123;'gender': 'M', 'job': 'Engineer'&#125; 和可变参数类似，也可以先组装出一个dict，然后，把该dict转换为关键字参数传进去： 123&gt;&gt;&gt; extra = &#123;'city': 'Beijing', 'job': 'Engineer'&#125;&gt;&gt;&gt; person('Jack', 24, city=extra['city'], job=extra['job'])name: Jack age: 24 other: &#123;'city': 'Beijing', 'job': 'Engineer'&#125; 或者 123&gt;&gt;&gt; extra = &#123;'city': 'Beijing', 'job': 'Engineer'&#125;&gt;&gt;&gt; person('Jack', 24, **extra)name: Jack age: 24 other: &#123;'city': 'Beijing', 'job': 'Engineer'&#125; 2.2.6 命名关键字参数对于关键字参数，函数的调用者可以传入任意不受限制的关键字参数。至于到底传入了哪些，就需要在函数内部通过kw检查。 仍以person()函数为例，我们希望检查是否有city和job参数： 12345678def person(name, age, **kw): if 'city' in kw: # 有city参数 pass if 'job' in kw: # 有job参数 pass print('name:', name, 'age:', age, 'other:', kw) 但是调用者仍可以传入不受限制的关键字参数： 1&gt;&gt;&gt; person('Jack', 24, city='Beijing', addr='Chaoyang', zipcode=123456) 如果要限制关键字参数的名字，就可以用命名关键字参数，例如，只接收city和job作为关键字参数。这种方式定义的函数如下： 12def person(name, age, *, city, job): print(name, age, city, job) 和关键字参数*kw不同，命名关键字参数需要一个特殊分隔符，*后面的参数被视为命名关键字参数。 调用方式如下： 12&gt;&gt;&gt; person('Mark', 24, city='hangzhou', job='Engineer')Mark 24 hangzhou Engineer 第三、列表生成式 List Comprehensions，是Python内置的非常简单却强大的可以用来创建list的生成式 举例： 123456789101112131415&gt;&gt;&gt; [x*x for x in range(1,11)][1, 4, 9, 16, 25, 36, 49, 64, 81, 100]&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; [m + n for m in 'ABC' for n in 'XYZ']['AX', 'AY', 'AZ', 'BX', 'BY', 'BZ', 'CX', 'CY', 'CZ']&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; d = &#123;'x': 'A', 'y': 'B', 'z': 'C' &#125;&gt;&gt;&gt; for k, v in d.items():... print(k, '=', v)...y = Bx = Az = C 第四、生成器 generator 如名字，其就是一个生成我们所需数据的容器，而不像 列表生成式，计算出所有数据。因此节省了空间，也解决了时间 123&gt;&gt;&gt; g = (x * x for x in range(10))&gt;&gt;&gt; g&lt;generator object &lt;genexpr&gt; at 0x1022ef630&gt; 遍历: next(g) 1234567891011121314&gt;&gt;&gt; g = (x * x for x in range(10))&gt;&gt;&gt; for n in g:... print(n)... 0149162536496481 yeild可中断当前操作，使函数成为 生成器 而不是普通函数 举例： 杨慧三角 123456 1 1 1 1 2 1 1 3 3 1 1 4 6 4 11 5 10 10 5 1 123456789101112def yanghu(n): L=[1] while 1: yeild L L = [L[x] + L[x+1] for x in range(len(L) -1)] L.insert(0,1) L.append(1) if len(L)&gt;n: breakfor n in yanghu(10): print n 小结本篇用一些简单的例子来讲解了下基础知识。 多动手练练哦]]></content>
      <categories>
        <category>Python新手引导</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Python爬虫利器---PhamtomJS]]></title>
    <url>%2F2017%2F07%2F03%2FPython%E7%88%AC%E8%99%AB%E5%88%A9%E5%99%A8---PhamtomJS%2F</url>
    <content type="text"><![CDATA[Python爬虫利器—PhamtomJS 阅读本文需要2.66分钟 python爬虫玩多了之后，大家应该会发现有个共性：就是只能爬取单纯的html代码。那么如果页面是JS渲染的该怎么办？ 如果我们单纯的去分析每一个后台的请求，手动去摸索JS渲染的一些结果，那么简直是醉了。所以，我们一些好用的工具来帮助我们像浏览器一样渲染JS处理的页面。 PhamtomJS http://phantomjs.org 引用官网的一句简介: ###Full web stack No browser required PhantomJS is a headless WebKit scriptable with a JavaScript API. It has fast and native support for various web standards: DOM handling, CSS selector, JSON, Canvas, and SVG. PhamtomJS是一个无界面的，可脚本编程的WebKit浏览器引擎。它原生支持多种web标准：DOM操作、CSS选择器、JSON、Canvas以及SVG。 具体的安装方法我们就不讲了。这里给个链接 http://www.tuicool.com/articles/MjUfayI 那么接下来我们通过抓取 Github 某个仓库渲染之后的主页来进行PhamtomJS的讲解： 效果: 12345678from selenium import webdriverdef capture(url, save_fn="capture.png"): print url browser = webdriver.PhantomJS() # Get local session of firefox browser.set_window_size(1200, 900) browser.get(url) browser.save_screenshot(save_fn) browser.close() print driver.find_element_by_tag_name(“div”).textprint driver.find_element_by_csss_selector(“#content”).textprint driver.find_element_by_id(“content”).text 1234find_element_by_tag_name(&quot;div&quot;)find_element_by_csss_selector(&quot;#content&quot;)find_element_by_id(&quot;content&quot;)等等的]]></content>
      <categories>
        <category>Python新手引导</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Python新手引导第一篇]]></title>
    <url>%2F2017%2F07%2F03%2FPython%E7%8E%AF%E5%A2%83%E5%87%86%E5%A4%87%2F</url>
    <content type="text"><![CDATA[Python新手引导 第一篇 阅读本文需要3.66分钟 目前比较流行的Python版本有2.x 和3.x,不过本人将介绍兼容所有版本的神器 Python简介 pyenv mac、Linux、Windows下安装Python 一、Python简介 Python是由著名的“龟叔”Guido van Rossum在1989年，为了打发无聊的圣诞节而编写的一个编程语言 以下数据是通过 TIOBE获取到的一组编程语言排行榜： 总的来说，这几种Top编程语言各有千秋。C是可以用来编写操作系统、最贴近硬件的语言。而Python是用来编写应用程序的高级编程语言。 然而Python最大的好处就是有很多现成的组件让你来用，就类似让你去搭建发送邮件的自动化工具，如果从底层发送邮件开始，那么我觉得你可能需要一年半载来完成这个工作。那么这时候就体现出来Python的重要性，只需要十行左右的代码你就可以轻松的发送邮件。 Python为我们提供了大量的基础代码库，覆盖了网络、文件、GUI、数据库、文件等等大量的内容。 在Pypi你可以搜索到任何你想用到的库。 当然Python也是有缺点的，如运行速度慢、代码不能加密等等的。其实总而言之这些都可以忽略，因为上层的编译语言永远都快不过C语言。 二、Pyenv 当前比较流行的Python版本包括了2.x 和3.x，但是有些代码需要在2.x也有一部分是在3.x因此Python环境的管理是必须要有的。 Pyenv是一个Python版本管理器 A)安装Pyenv在终端执行如下命令以安装 pyenv 及其插件：1curl -L https://raw.githubusercontent.com/yyuu/pyenv-installer/master/bin/pyenv-installer | bash 安装完成后，根据提示将如下语句加入到~/.bashrc中：1234export PYENV_ROOT=&quot;$HOME/.pyenv&quot;export PATH=&quot;$PYENV_ROOT/bin:$PATH&quot;eval &quot;$(pyenv init -)&quot;eval &quot;$(pyenv virtualenv-init -)&quot; # 这句可以不加 B)使用pyenv 总共有11条不同的命令，具体可见：Comment Reference.下面就最重要的几条进行说明： 1. pyenv versions查看当前pyenv可检测到的所有版本，处于激活状态的版本前以 * 标注. 2. pyenv version查看当前处于激活状态的版本，括号中内容表示这个版本是由哪条路径激活的 3. pyenv install使用python-build(插件)安装一个Python版本，到$PYENV_ROOT/versions路径下1pyenv install -v 3.4.7 4. pyenv uninstall卸载一个版本 5. pyenv rehash为所有已安装的可执行文件创建shims,因此，每当你增删了Python版本或者带有可执行文件的包(如pip)以后，都必须执行一次该命令 12python install -v 3.4.7python rehash 6. pyenv global设置全局的Python版本，通过将版本写入~/.pyenv/version文件的方式。1pyenv global 3.4.0 7. pyenv local设置面向程序的本地版本。该方式优先级高于global。1pyenv local 3.4.7 8. pyenv shell设置面向shell的Python版本，通过设置当前 shell的PYENV_VERSION环境变量的方式。这个方式的优先级比local、global都高。 –unset可以取消当前shell设置的版本12pyenv shell pypy-2.2.1pyenv shell --unset 三、安装Python环境因为Python是跨平台，因此它可以运行在Windows、mac和各种Linux/Unix系统上。不过个人建议使用Mac，若因为穷，那么可以选择Linux/Unix。因为Windows的终端用到你吐，虽然可以在Windows上安装其他的终端程序，但是还是解决不了体验。 A) 在Mac上安装PythonOSX 10.8+都自带了2.7版本的Python.要安装最新的Python可使用brew install python3来搞定 B) 在Linux上安装Python当前熟悉Linux的自行安装Python就可以了。否则，还是换到Windows上。 小结安装成功之后，打开终端，输入python就可以了。]]></content>
      <categories>
        <category>Python新手引导</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[编写高质量的Pythonic风格代码]]></title>
    <url>%2F2017%2F07%2F03%2F%E7%BC%96%E5%86%99%E9%AB%98%E8%B4%A8%E9%87%8F%E7%9A%84Pythonic%2F</url>
    <content type="text"><![CDATA[来自公众号: DeveloperPython 我知道有些新人肯定不了解Pythonic是什么，也许在某些论坛看到过这个词语。其实，它的意思很简单。这是Python的开发者用来表示代码风格的名词。它是在Python开发过程中指定的一种指南，一种习惯。宗旨是 123456789101112131415161718192021222324252627282930313233343536373839404142&lt;!--more--&gt;### 1、不用害怕长变量名长一点的变量名，有时候是为了让程序更容易理解和阅读。并且，有的编辑器已经支持自动提示，所以不用太担心敲键盘太多的烦恼。比如: user_info 就是比 ui 的可读性高很多:user_info = &#123;&apos;name&apos;:&apos;xiyouMc&apos;,&apos;age&apos;:&apos;保密&apos;,&apos;address&apos;:&apos;Hangzhou&apos;&#125;### 2、避免使用容易混淆的名称尽量不要使用 ```内建``` 的函数名来表示其他含义的名称。比如 list、dict等。不要使用 o(字符O的小写，很容易被当做数字0)，1(字母 L 的小写，也容易和数字 1 混淆)其次，变量名最好和你要解决的问题联系起来。### 3、尽量不要使用大小写来区分不同的对象比如 b是一个树脂类型的变量，但 A 是 String 类型，虽然在编码过程中容易区分这两者的含义，但是没啥卵用，它并不会给其他阅读代码的人带来福利。反而，带来的呕吐的感觉。### 4、其次，最重要的一点是，多看源码，学习别人的风格Github 上有数不胜数的优秀代码，比如web框架里面有名的Flask、Requests，还有爬虫界的Scrapy，这些都是经典中的经典，并且都是比较好的理解pythonic代码风格精髓的例子。### 5、最后，你实在是懒得不想关注这些，只想写代码，那么。。。我推荐一个神器，在你写完代码之后，执行这个神器就可以看到检测代码风格后的结果。```PEP8```，全称，&quot;Python Enhancement Proposal #8&quot;，它列举除了很多对代码的布局、注释、命名的要求。pip install -U pep8 #来安装 pep8z然后用它来检测代码：```python➜ /Users/xiyoumc &gt;pep8 --first pornHubSpider.pypornHubSpider.py:1:1: E265 block comment should start with &apos;# &apos;pornHubSpider.py:19:43: E124 closing bracket does not match visual indentationpornHubSpider.py:22:16: E251 unexpected spaces around keyword / parameter equalspornHubSpider.py:53:5: E301 expected 1 blank line, found 0pornHubSpider.py:71:22: W503 line break before binary operator 同时，如果对pep8感兴趣的话，可以留言，我可以开个系列来讲解 PEP8里面的变量、函数、类、木块和包，这样就会更加容易的理解Pythonic风格。 最后，如若我写的对大家有点帮助，那么关注公众号 DeveloperPython，你将会收到关于Python技术第一时间的推送 长摁‘识别二维码’，一起进步 生活不止眼前的苟且，还有手下的代码、 和嘴上的扯淡——个人博客: http://xiyoumc.0x2048.com/ Github:https://www.github.com/xiyouMc 点击 Join，加入Python技术成长圈子，我在这里等着你。]]></content>
      <categories>
        <category>Python新手引导</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Python新手引导第二篇]]></title>
    <url>%2F2017%2F07%2F03%2FPython%E6%96%B0%E6%89%8B%E5%BC%95%E5%AF%BC%20%E7%AC%AC%E4%B8%89%E7%AF%87%20Python%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[Python新手引导 第三篇-Python基础和字符编码 ###阅读本文需要4.66分钟 有其他计算机语言基础的同学，阅读本篇基础部分建议1到2分钟。 基础类型、变量和字符编码 list 和 tuple 第一、基础类型、变量和字符编码 计算机能处理的数据类型有很多，包括文本、图形、音频、视频等等的。上层语言对其不同的数据，定义了各自不同的数据类型。如Java的int、String、boolean，JS的var等等的。Python也不例外： 1.1 基础类型 整数 Python可以处理任意大小的整数，包括负整数。1、100、-9191等等。 浮点数 浮点数也就是小数。之所以称之为浮点数。是因为其小数点是可变的，比如：1.23x10^5 和12.3x10^4是一样的。也就是类似的科学计数法 1.23e5和12.3e4。因此浮点数在计算机存储的时候可能就会有四舍五入的情况 字符串 ‘ 或者 “括起来的任意文本 布尔值 True和False, 同时可以使用and or not来运算 空值 Python中使用None来表示空值，其不是0的意义 1.2 变量 变量在程序中就是用一个变量名标书，且区分大小写，可用数字和_表示，并不能以数字开始 a = ‘aaa’ Python解释器会在内存中创建aaa的字符串 并在内存中创建一个名为a的变量，并将其指向aaa 1.3 字符编码 最原始的由歪果仁定义的ASCII编码，使用127个字符，从A(65)到z(122). 其次就是各国的编码，如我们所知的GB2312将中文编进去。还有其他国家的类似，日本的Shift_JIS等等。如此一来，你会发现各国都有自己的编码，那么岂不是各种乱码。因此Unicode就因此诞生了。Unicode将所有编码统一到了一套编码中，这样就解决了乱码的问题。 Unicode和ASCII编码的区别：Unicdeo使用两个字节、ASCII使用一个字节 举个栗子 字符 ASCII Unicode A 十进制（65）,二进制(01000001) 0A (00000000 01000001) 因此你会发现如果你的文本全是英文的，使用Unicode编码的话，那么需要多一倍的存储空间，导致存储和传输上十分低效率。 UTF_8应景而生，是一种可变长编码.UTF_8编码把一个Unicode字符根据不同的数组大小编码成1-6个字节，常用的英文被编码成1个字节，汉字使用3个字节。如果要传输的文本包含大量的英文字符，用UTF-8编码能节省很多空间： 字符 ASCII Unicode UTF-8 A 十进制（65）,二进制(01000001) 0A (00000000 01000001) 01000001 中 01001110 00101101 11100100 10111000 10101101 所以在计算机的内存中，统一使用Unicode编码，但是需要保存到硬盘或者传输的时候，就会使用到UTF-8编码。因此在计算机上打开某个文本的时候，会首先以Unicode将其独到内存中，当修改保存的时候，又会使用UTF-8。 使用Unicode表示的str可以通过encode()转换为指定的bytes,例如： ‘A’.encode(‘ascii’) b’A’ b’\xe4\xb8\xad\xe6\x96\x87’.decode(‘utf-8’) ‘中文’ len()可计算str包含多少个字符,len(‘abc’) = 3 在操作字符串时，我们经常遇到str和bytes的互相转换。为了避免乱码问题，应当始终坚持使用UTF-8编码对str和bytes进行转换。 由于Python源代码也是一个文本文件，所以，当你的源代码中包含中文的时候，在保存源代码时，就需要务必指定保存为UTF-8编码。当Python解释器读取源代码时，为了让它按UTF-8编码读取，我们通常在文件开头写上这两行： 12#!/usr/bin/env python3# -*- coding: utf-8 -*- 第二、List和tuple 集合在每个语言中都有，当然Python也不例外。 2.1 ListPython内置的列表数据类型。一种有序的集合，可随时添加和删除其中元素1name = [&apos;Mark&apos;,&apos;xiyouMc&apos;,&apos;Alison&apos;] 访问方式可直接通过索引: name[0] name[1] 当然索引是从0开始到len(name) - 1 区别去其他语言，Python可以通过 name[-1]访问到最后一个元素，一次类推 -2可以访问到倒数第二个。 list是一个可变的有序表，所以可以在list的末尾追加元素: name.append(&#39;Ali&#39;) 同样也可以插入元素, name.insert(1,&#39;Baidu&#39;) 删除尾部元素使用pop(),并可以指定删除某个元素 pop(1) 赋值（替换）： name[1] = &#39;Tencent&#39; 多层List：s = [&#39;Mark&#39;,&#39;java&#39;,[&#39;nlp&#39;,&#39;php&#39;]],这样通过 s[2]拿到的也是一个list. 当然要拿到 nlp的话，直接s[2][1]即可 2.2 tuple 和List一样，tuple也是一个有序列表。唯一和list有区别的就是 tuple一旦被初始化就不能修改 1name = (&apos;Mark&apos;,&apos;Alison&apos;,&apos;xiyouMc&apos;) 即tuple没有 append insert函数。 a = (1,)表示只有一个元素的tuple. 当然如果tuple中包含list那么这个list是可变的,因此tuple中保存的只是list的指针，如： 123a = (&apos;A&apos;,[&apos;B&apos;,&apos;C&apos;])a[1][1] = &apos;D&apos;(&apos;A&apos;,[&apos;D&apos;,&apos;C&apos;]) 小结本篇主要讲了计算机的基础知识–编码，看过这篇文章之后，以后遇到乱码的问题，相信你不用再百度了。 其次就是Python中常用到的基础类型和集合，玩一玩吧…少年]]></content>
      <categories>
        <category>Python新手引导</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Shell语言基本教程]]></title>
    <url>%2F2017%2F07%2F03%2Flinux_shell%2F</url>
    <content type="text"></content>
      <categories>
        <category>技术</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Mac、Linux安装libimobiledevice]]></title>
    <url>%2F2017%2F07%2F03%2Flibimobiledevice%2F</url>
    <content type="text"><![CDATA[linux连接iOS设备并且安装ipa应用Android有个adb命令，可以很方便的做一些事情，比如直接安装应用。但是因为苹果比较封闭，没有直接的命令可以使用。但是有大牛做出了这样的东西–libimobiledevice 关于libimobiledevice的描述A library to communicate with services of Apple iOS devices using native protocols. ibimobiledevice又称libiphone，是一个开源包，可以让Linux支持连接iPhone/iPod Touch等iOS设备。由于苹果官方并不支持Linux系统，但是Linux上的高手绝对不能忍受因为要连接iOS设备就换用操作系统这个事儿。因此就有人逆向出iOS设备与Windows/Mac Host接口的通讯协议，最终成就了横跨三大桌面平台的非官方版本USB接口library。经常用Linux系统的人一定对libimobiledevice不陌生，但是许多Windows和Mac用户也许就不知道了。事实上，它同iTools一样，都是可以替代iTunes，进行iOS设备管理的工具。因为源码是开放的，可以自行编译，所以对很多开发者而言可以说更为实用。 可以自行到GitHub上下载编译https://github.com/libimobiledevice/libimobiledevice 不过这里用简单的方式分别在mac已经ubuntu上进行安装 在mac下安装可以使用brew，brew安装方法可以自行百度1234 sudo brew update sudo brew install libimobiledevice#libimobiledevice中并不包含ipa的安装命令，所以还需要安装 sudo brew install ideviceinstaller ubuntu下安装需要添加一个新的软件库，里面包含了libimobiledevice1234sudo add-apt-repository ppa:pmcenery/ppasudo apt-get updateapt-get install libimobiledevice-utilssudo apt-get install ideviceinstaller 这里面包含了很多命令，如下 如要安装一个ipa文件到手机上可以使用ideviceinstaller -i 命令安装一个ipa文件到手机上，如果是企业签名的，非越狱机器也可以直接安装了]]></content>
      <categories>
        <category>技术</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[插件化框架简介]]></title>
    <url>%2F2017%2F07%2F03%2F%E6%A1%86%E6%9E%B6%E7%AE%80%E4%BB%8B%2F</url>
    <content type="text"><![CDATA[本框架是建立在 Dynamic-load-apk进行的上层封装。增加插件动态加载到libs目录和针对模块Service的注入。 本文将以H5Core为插件进行讲解。 更新日志：&gt; 2016/7/6 commit -m “增加懒加载功能” hash: 2a335dc49654c80fb6779cacefdf3ed712c23a8 插件化框架简介 插件化是将Apk中功能类似的模块封装到独立的Application中，并根据框架约定好的规则完成Apk的动态加载和Service的注入。 本框架是将每一个Apk作为so并使用定制化打包脚本将so文件打到主Project/libs/jniLibs，这样在apk编译的时候就可以将so文件直接装载进data/data/xxxxx/lib目录，支持后续的DexClassLoader加载该文件。 每一个模块分为Api和Core，Api作为模块对外提供的接口，Core作为封装好的独立模块，每一个模块做好自己的混淆。注入操作需在Core中定义，下文将介绍这块。 主Client增加bundleList.config文件，文件配置： bundleName=h5core //直接加载的插件 lazyBundle=h5core.H5Service&amp;H5Api //懒加载插件 一、Framework Framework提供了一个动态加载apk的框架，并提供一个加载独立模块的BaseMateinfo。 简介 开发模块时需要在 module(core)/package name/下定义Metainfo继承自BaseMateinfo。 这样该模块在主Apk安装的时候就会动态将模块的接口注入到框架，后续提供给其它组件调用。 模块提供的主要方法类有:BasePluginActivity,BasePluginFragmentActivity,BasePluginService,BaseMateinfo,MarkApplication. BasePluginActivity: 基础的Activity，每一个模块中的Activity都需要继承该类，完成模块中的Activity的代理化。 BasePluginFragmentActivity： 基础的FragmentActivity，同上。需要继承该类 BasePluginService: 基础的Service，同上。 BaseMateinfo: 模块Service注入的基类，其它模块的Core层都需要定义一个Metainfo来继承该类，并完成Service的注入。（后面会介绍如何注入） MarkApplication:模块的Application，可以拿到模块的Context，并提供查找Service，启动Activity等方法。 二、Activity层 为了让proxy全面接管apk中所有activity的执行，需要为activity定义一个基类BaseActivity，在基类中处理代理相关的事情，同时BaseActivity还对是否使用代理进行了判断，如果不使用代理，那么activity的逻辑仍然按照正常的方式执行，也就是说，这个apk既可以按照执行，也可以由宿主程序来执行。 独立模块架构 模块分类：Api和Core,针对不同业务可追加前缀。 每一个模块对外提供一个Service供其他模块引用。Service的Interface类放在Api模块，实现类放在Core。实现独立模块的封装。 Service注册：在Core的根包目录创建MetaInfo类，继承Framework模块的BaseMetaInfo.如下： public class MetaInfo extends BaseMetaInfo { private static final String TAG = &quot;MetaInfo.Init&quot;; public MetaInfo() { Log.d(TAG,&quot;Service init&quot;); ServiceDescription serviceDescription = new ServiceDescription(); serviceDescription.setInterfaceName(XXService.class.getName()); serviceDescription.setClassName(XXServiceImpl.class.getName()); services.add(serviceDescription); } } 注解: ServiceDescription类是针对Service的描述类，将接口和实现封装在该对象，并将其添加到services列表中。 以上工作就完成了模块的注入。 模块之间依赖 模块只要是通过Api包的依赖进行访问。由于Api是作为一个Jar存在的，因此可以直接被其它模块依赖，并切记使用 provided来依赖，防止Api的jar包被编译进模块。 模块之间访问：主要的类有MarkApplication、MicroApplicationContext。 比如其他模块访问Core: XXService xxservice = MarkApplication.getInstance().getMicroApplicationContext().findServiceByInterface(XXService.class.getName()); 这样就可以拿到容器的Service，从而调用其提供的方法。 模块内部资源的访问 由于每一个模块作为独立的apk打入主apk,因此访问该apk的上下文不再是该apk的，而是框架层的代理上下文。 示例： 1、Resourse获取 MarkApplication.getInstance().getMicroApplicationContext().getResourcesByBundle(&quot;xxcore&quot;); 2、Assets获取 MarkApplication.getInstance().getMicroApplicationContext().getAssetsByBundle(&quot;xxcore&quot;); Gradle打包命令详解 gradle build ：编译当前模块。 gradle buidleJar:针对本模块生成jar包，保存目录在 xxx/build/libs/xxxx.jar gradle uploadArchives:上传本项目包到Nexus服务器，提供给其他模块依赖 例子： 1、Api包的build.gradle模版2、Core包的 build.gradle模版 三、依赖关系介绍 如今模块化之后，依赖关系的复杂度也相比之前复杂了不少，因此梳理好依赖关系是必须考虑的问题。 模块化主要的依赖关系：框架主要有Portal、Framework、Module三个模块： 1、Portal是项目的Launcher目录。 2、Framework是框架的架构模块。 3、Module是每一个模块，并分为Api和Core，并且Api作为Android.library、Core作为Android.application. 4、每一个模块通过依赖其它模块的Api进行组件的调用。并且每一个Core都需要依赖Framework。 插件apk的开发规范开发插件apk所需要遵循的规范： 1. 不能用this：因为this指向的是当前对象，即apk中的activity，但是由于activity已经不是常规意义上的activity，所以this是没有意义的 2. 使用that：既然this不能用，那就用that，that是apk中activity的基类BaseActivity中的一个成员，它在apk安装运行的时候指向this，而在未安装的时候指向宿主程序中的代理activity，anyway，that is better than this. 3. 不能直接调用activity的成员方法：而必须通过that去调用，由于that的动态分配特性，通过that去调用activity的成员方法，在apk安装以后仍然可以正常运行。 启动新activity的约束：启动外部activity不受限制，启动apk内部的activity有限制，首先由于apk中的activity没注册，所以不支持隐式调用，其次必须通过BaseActivity中定义的新方法startActivityByProxy和startActivityForResultByProxy，还有就是不支持LaunchMode。 目前暂不支持Service、BroadcastReceiver等需要注册才能使用的组件。 四、更新功能 2016/7/6 懒加载功能 1、bundleList.config 文件增加lazyBundle字段来标示是否进行懒加载。字段值格式：bundleName.bundleService*bundleService。这样在该插件被调用的时候，框架采取load这个dex。 2、优化效果：681kb的so，首次启动懒加载优化100ms。 Thankd for your reading, by Mc… Thanks Dynamic-load-apk update Contact meAny further question? Email me please! LicenseCopyright 2016 xiyouMc Licensed under the Apache License, Version 2.0 (the &quot;License&quot;); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an &quot;AS IS&quot; BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.]]></content>
  </entry>
  <entry>
    <title><![CDATA[当我玩哔哩哔哩的时候，一不小心。。。]]></title>
    <url>%2F2017%2F07%2F03%2F%E5%BD%93%E6%88%91%E7%8E%A9%E5%93%94%E5%93%A9%E5%93%94%E5%93%A9%E7%9A%84%E6%97%B6%E5%80%99%EF%BC%8C%E4%B8%80%E4%B8%8D%E5%B0%8F%E5%BF%83%E3%80%82%E3%80%82%E3%80%82%2F</url>
    <content type="text"><![CDATA[一不小心用代码登陆了B站。。。并上传了。。视频 阅读本文需要4.66分钟 你被标题吸引了吧。。。别急着关。。重头戏在后面 最近当我玩B站的时候，一不小心用代码登录了它，并几乎无限制的上传视频。 那么接下来，我来讲解如何通过Hack技术来模拟 哔哩哔哩 的登录，并完成我们的视频上传等操作。因此内容中略有“暴力”，若您感到不适，那还是也请看完它。 按照以往的老套路，我们首先需要弄清楚它的登录逻辑，并通过我们的代码来实现登录操作，其次拿到所谓的 Cookie 或者 Token、Sign等校验字段来做其他的操作，以下将围绕 B站 一步步来讲解破解的思路: 首先我们访问到 哔哩哔哩 的登录页面: 当我们在未登录的状态下访问登录页面的时候，会发现验证码已经显示出来了。那么他们是怎么做到当我输入账号、密码并输入一个已经出来的验证码之后就能校验成功呢。这时候就得提前动动脑子，当然如果你是开发服务器的话，应该明白里面的道理。这里我简单的讲下，其实在访问这个登录页面的时候，B站 已经将一个唯一的标识和验证码绑定起来了（也就是后面说到的Cookie），并且在登录的时候将这个标识一并发送上去。也就是说：通过一个标识来绑定验证码和登录操作。 那么接下来我们看看在第一次访问登录页面的时候，都有哪些可用的数据,打开 Charles 抓包工具(Charles抓包工具可在历史文章中找到)，重新访问登录页面. 这是登录页面的Request数据:当然一眼看上去并没有什么可用数据。其实确实是没什么卵用的数据.那么我们来看看Response数据:一眼看上去是挺乱的。细看下它的Raw数据。其中包括了使用的Server、Set-Cookie等等的数据，还有登录页面的html文本. 那么其中最重要的数据也就是 Set-Cookie，这个Set-Cookie中的数据就是之前讲到的 用来和验证码绑定的唯一标示。那么我们来确认下，来看看验证码图片的包:快看，快看 验证码 Request 中的 Cookie，果然是上面登录页面的 Response 的 Set-Cookie。 那么验证码就简单了，我们通过代码来访问 B站 的登录页面，并拿到Response的Set-Cookie，然后再将这个Set-Cookie放到下载验证码Request的Cookie中，就这样，我们的验证码搞定了，那是不是登录就很简单了，少年憋急。登录才是大头.. 来来来，基于上面的登录页面，我们在里面输入自己的账号，并完成登录来看看发的包都有哪些. 登录操作之后的Request:可以看出来这是一个 post 请求，当然 Cookie 和验证码的一样将之前保存下来的 Set-Cookie 传给Request的Cookie. post 参数如下:Orz,WTF，提交的密码加密了。那么我就需要来找一下它的加密算法了。其实网页端的加密并没有什么卵用。对我来说，就是随便翻翻代码的事（毕竟我很帅）。 来来来，找啊找啊找加密。然后我们先试探性的搜索下请求的字段 ‘pwd’ 如下图:果然定位到了加密的位置，当然前端页面的加密大部分都是很容易找到的，只要你有耐心.以上就是 B站 加密密码的算法。简单讲下就是：通过 /login?act=getkey 拿到一个数据(hash,key),并以key作为RSA算法的公钥来加密 (hash+明文密码),然后针对这个数据来一次base64即可 python实现如下: 1234import rsapub = rsa.PublicKey.load_pkcs1_openssl_pem(_key)_pwd = rsa.encrypt((_hash + psw).encode(),pub)_real_pwd = base64.b64encode(str(_pwd)) 那么现在我们就需要把问题聚焦到 /login?act=getkey 这个接口上。那么我们再回到之前的抓包数据上，会发现果然有一个 getkey 的请求:同上，Cookie是最开始的Set-Cookie。Response中也就同时拿到了我们需要的 hash 和 key.大功告成，所有请求和加密都被我们搞定。 这时候我们再思考下登录脚本应该怎么判断是否登录成功呢，回头过来看下之前的登录操作的结果 也就是 上面的 dologin 接口.会发现如果你成功登录之后，在 dologin 接口上会有 302 重定向跳转，并最终跳转到 主页上。因此这时候我们就可以来写代码，模拟登录，并且在最后一步登录请求中判断当前请求历史的第一个状态码是不是 302 ，如果是302，说明我们的登录脚本是没问题的。同时，再拿到 dologin的Response中的Set-Cookie作为新的Cookie，因为这个Cookie才是真正验证通过的Cookie，当然它是存在有效期的。具体多少我还不清楚，一般有一个礼拜、一个月、甚至一年之久。之后我们用这个Cookie去做其他有意义的事情，是完全没问题的。 其次就是上传视频接口，也是类似的方法，需要分析上传视频的接口数据。并将最终的Cookie携带到请求包中。其中需要注意的是B站的上传视频可简单的分为以下几个步骤： 将视频以Chunk的方式，而且是options的请求方式上传到服务器。因此它是支持断点续传的。 拿到options请求之后的视频id，再请求 add 接口将数据post上去即可 总结虽然这篇文章很短，但是当你真正坐下来分析的时候，将是一段非常枯燥的过程。需要的就是你的耐心。 其次之所以写这篇文章，其实重点不是怎么去破解B站的登录，而是这些破解的逻辑是否可以提供给我们一些服务器架构的思路，抑或防范别人的破解。]]></content>
      <categories>
        <category>Python新手引导</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Python爬虫如何入门？]]></title>
    <url>%2F2017%2F07%2F03%2F%E7%88%AC%E8%99%AB%E5%A6%82%E4%BD%95%E5%85%A5%E9%97%A8%EF%BC%9F%2F</url>
    <content type="text"><![CDATA[Python爬虫如何入门？ 源自公众号:DeveloperPython扯淡其实，“入门”最好的方式是以项目开始，这样实践起来你会被目标驱动。从而，不用一步一步慢慢的学习模块化的东西。 其实，知识体系里面的每一个知识点类似于图里的点。边就是知识体系的依赖关系，那么整个图也就是一个有向无环图。因为学习A的经验可以帮助到你学习B。因此，入门的东西根本不用学习，因为入门点根本不存在。 同时，你需要学习的是如何去做一个大的项目，来亲身体会爬虫， 并一步步学习爬虫的知识点。 那么，我总结下在其他平台上的相关知识点和自己的想法： 爬虫的工作原理 基本的Https爬虫工具：Scrapy 分布式爬虫系统。也就是维护一个集群机器来高效的完成分布式队列。Github上也有一个现成的例子: nvie/rq rq和Scrapy的结合： rolando/scrapy-redis 后续处理: 网页处理grangier/python-goose 存储(Mongodb) 以下，我将基于xiyouMc/WebHubBot的经验来讲： 一、 爬虫的怎么工作的爬虫的另一个意思其实就是🕷（Spider） ，互联“网”就是它的环境。简单的来说，也就是你需要用这个蜘蛛来把相关网站的所有角落(网页)都爬一边。 那么，你可以选择一个自己感兴趣的平台，如知乎、淘宝等等的。 我这里通过PornHub来讲解。 比如，我们访问PornHub的首页，里面会出现很多链接。最初我们的目标是拿到该站中所有的视频标题、视频简介、视频链接或者其他有用信息。然后我们兴高采烈的将整个首页都爬下来，这里可以理解为你就是将整个页面完完整整的Copy了下来。 然后，我们随便点击一个链接进入视频详情页，进入第二个页面之后，就会看到具体的视频标题、简介等等的。那么这只是一个视频信息，我们又是如何做到爬取整站的数据呢。这里可以动下脑子，一种是返回到首页去拿另一个链接，另一种则是基于第一步爬下来的首页来找下一个链接。这里，当然是第二种方案。同时我们要做去重，爬过的链接，就不要再去爬第二遍。 所以，理论上如果后续的所有视频详情页都是从首页可达的话，那么我们就一定可以将所有网页都爬下来。 以下是Python的伪代码实现: 123456789101112131415161718 from Queue import Queuehome_page = 'https://www.pornhub.com/'link_queue = Queue()seen = set()seen.insert(home_page)link_queue.put(home_page) while(True): if link_queue.size() &gt; 0: current_url = url_queue.get() #拿到队列中第一个url links = save(current_url) #保存这个页面的html，并返回当前页面的所有link for link in links: if link not in seen: seen.put(link) link_queue.put(link) else: break 以上就是一个简单的伪代码来爬取pornhub中视频资源的例子。当然， 这只是一个非常简单的例子，其实爬虫是一个非常复杂的项目，类似的就是搜索引擎需要爬取整站的数据，更是需要一整个团队来开发和维护。 二、 效率如果，使用上述的代码来爬取PornHub的话，那么你是绝对无法在一天时间内完成500万的海量数据，更别说在短时间内爬取PornHub的所有数据。 那么，问题出在哪？爬的网页太多太多了，而且上面的代码太慢太慢了。 PornHub的全网有N个页面，那么分析下判重的时间复杂度将是 N * log(N)，因为每个网页都要遍历一遍，而使用Set来做判重，需要 log(N) 的复杂度。 所以，我们需要一个成熟的判重方案。Bloom Filter。 它是一个空间效率很高的随机数据结构。官方简介： Bloom Filter是一种空间效率很高的随机数据结构，它利用位数组很简洁地表示一个集合，并能判断一个元素是否属于这个集合。Bloom Filter的这种高效是有一定代价的：在判断一个元素是否属于某个集合时，有可能会把不属于这个集合的元素误认为属于这个集合（false positive）。因此，Bloom Filter不适合那些“零错误”的应用场合。而在能容忍低错误率的应用场合下，Bloom Filter通过极少的错误换取了存储空间的极大节省。 有兴趣可以详细学习下这个算法。 简单的来说，它是一种利用Hash的方法来判重的。并且在使用固定的内存，不随url的数量增加而增长,以 O（1）的效率判断url是否已经在set中。但是仍然有极小的可能性会误判，所以对于“零错误”的系统不适用。但是对于爬虫，小概率的重复爬取也是可以接受的。 那么，以上就是判重的最快方式了。 当然，另一个瓶颈又会出现，如果你只有一台机器，那么不管你的带宽有多大你的机器下载网页的速度还是会有瓶颈。那么，只有加快这个速度，我们使用多台机器来跑。 三、 集群化爬取集群化爬取，其实不难理解。也就是将你的爬虫任务分发到n台机器来处理，当然每台机器处理的任务不同，且不重复。 那么，假设你有100台机器，怎么用Python实现一个分布式的爬取算法呢？ Server -&gt; Client 。这种C/S 的模式，我相信大家也不陌生。那么分布式的系统，其实就是一台Server -&gt; n个Client 来处理。这里我们将Server定义为 Master机，多个Client定义为多个 Slave。所以基于开始的伪代码，我们可以将link_queue 放到Master上，其他的Slave都可以通过网络跟Master联通，每当一个Slave下载完成一个页面之后，就会将这个页面的结果告知Master，同时获取一个新的link 来爬取。同时 BloomFliter 也是放在Master的，用来针对Links进行去重。 其中Slave和Server联通的方式，就是通过Redis，这是一个可以远程操作的缓存数据库，提供了完善的队列管理。其次，Redis的队列中已经包含的去重的，当Push一个url 到Redis之后，某一个Slave Pop拿到数据，那么这个Url将只会在这个Slave进行处理。 因此，我们可以用Python来实现。Slave的机器上安装Scrapy，Master上安装Redis和rq用作分布式队列。 伪代码: 123456789101112131415161718192021222324"""Slave""" url = link_from_master() # 从Master机Get到最新的链接content = save(url) # 请求并保存这个链接下的视频信息send_to_master(url) # 将当前处理过的url Post给主机。 """Master"""queue = Queue()bf = BloomFilter() home_pages = "https://www.pornhub.com/" while(True): if request == 'GET': if distributed_queue.size()&gt;0: send(queue.get()) # 将当前url push到Redis，从而让Slave获取到。 else: break elif request == 'POST': bf.put(request.url) #将处理过的Url 保存到bf队列 轮子: rolando/scrapy-redis 四、 后处理上面的路子，其实是很简单很简单的一部分。同样的，后续你还要进行其他的处理，比如： 有效的存储 有效的判重 有效的信息提取 及时更新 所以，不要在意如何“入门”，只管上路就好了。 五、 更重要的一点 长摁‘识别二维码’，一起进步 生活不止眼前的苟且，还有手下的代码、 和嘴上的扯淡——个人博客: http://xiyoumc.0x2048.com/ Github:https://www.github.com/xiyouMc 六、 如何找到一群学习Python的朋友圈点击 Join，加入Python技术成长圈子，我们在这里等着你。]]></content>
      <categories>
        <category>Python新手引导</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[程序员都应该会的抓包工具--Charles]]></title>
    <url>%2F2017%2F07%2F03%2F%E7%A8%8B%E5%BA%8F%E5%91%98%E9%83%BD%E5%BA%94%E8%AF%A5%E4%BC%9A%E7%9A%84%E6%8A%93%E5%8C%85%E5%B7%A5%E5%85%B7-Charles%2F</url>
    <content type="text"><![CDATA[程序员都应该会的抓包工具-Charles 阅读本文需要7.66分钟 抓包 其实很多程序员都不陌生了，但是真正抓过包、分析过的又有几个。本文将介绍几款简单易用的抓包工具，并针对目前互联网主流的Http和Https网络包进行抓取并分析，同时分享手机抓包的技术1. Charles、Fiddler和Wireshark2. Http、Https及其原理3. 手机抓包4. Charles的附加功能一、抓包工具 Fiddler 是之前我用Window电脑的时候，特别喜欢用的工具，而且当时的Fiddler足以满足的我简单的抓包工作，现在也应该更新到Fiddler3了，如果用Windows的朋友可以用Fiddler3进行抓包。 Charles 自从换了Mac之后我就喜欢上了这个工具，不过Charles在Windows上同样也有。 Wireshark 这个我不是怎么经常用，这个抓包工具可以详细的看到网络请求的三次握手，并且可支持spdy、tcp等等的网络协议抓包，当然其他两个是不支持的。 我将以Charles为例分别抓取Http和Https包： 下载Mac破解版下载地址：http://download.csdn.net/detail/m694449212/9770583Win破解版下载地址：http://download.csdn.net/detail/m694449212/9770589官网链接，需要购买LisenseKey：https://www.charlesproxy.com/ 打开界面如下： 第二、Http、Https包2.1、Http包2.1.1 清理Charles列表，让抓包更加清晰 2.1.2 以我的CSDN为例（m694449212）,通过Chrome点击‘我的博客’，抓到需要的包 从中我们过滤出m694449212的博客包，但是这个过滤的过程需要我们去一个个找（当然如果你的经验比较足或者英语比较好的话，可以发现其实就是blog.csdn.net的包）2.1.3 分析包 2.1.4 Reuqest 其中比较重要的是Cookie,网站为了辨别用户身份、进行 session 跟踪而储存在用户本地终端上的数据（通常经过加密）.同时Cookie在我们爬虫的时候也是一个必不可少的东西，那么如何自动化获取Cookie呢？后面会讲解到。2.1.5 Response 获取Cookie,通过我以往的经验:a. 获取Cookie的时候首先需要保证我们的浏览器环境是干净的，我说的干净其实就是清楚当前浏览器保存的Cookie，并重启浏览器。b. 重启之后我们访问www.csdn.net，当前Host的Request中就不包含Cookie，那么Cookie在哪呢，其实细心点的会发现Cookie在Response的Headers-&gt;set-cookie中，并在下次请求中使用到。c. 那么当我们登录操作并携带Cookie在请求Headers中，那么登录成功之后该Cookie就会生效。之后我们的所有请求携带该Cookie就会是一个正常的请求，并能拿到需要的结果。关于某些请求携带sign参数的，后面的文章我会讲解到破解Sign函数（其实有时候不是直接的破解而是函数的Hook,有兴趣的可以提前了解下Android或者iOS的Hook，通过IDA找到sign函数,并使用cycript调用），之后的文章我会以国外的知名App Instagram为例，Hook它的签名函数。1来个美女提提神（图片来自Instagram的Https包数据），继续往下看 2.2、Https包2.2.1、Https简介SSL相信大家都不陌生。其实Https就是在Http基础上通过SSL协议进行加密之后的网络传输。并通过非对称和对称加密算法来对密码和数据进行加密。具体看下图： 1. Client明文将自己支持的一套加密规则、一个随机数(Random_C)发送给服务器.2. Server返回自己选择的加密规则、CA证书（服务器地址、加密公钥、以及证书颁发机构）、外加一个通过加密规则和HASH算法生成的随机数(Random_S)3. Client收到Server的消息之后会:1234a:验证证书（地址是否是正在访问的和机构是否合法）、b:自己生成一个随机的密码(Pre_master)并使用CA证书中的加密公钥进行加密(enc_pre_master)、c:计算出一个对称加密的enc_key,通过Random_C、Random_S、Pre_master、d:生成握手信息：使用约定好的Hash算法计算握手信息，并通过enc_key和约定好的加密算法对消息进行加密 4. Client将enc_pre_master、加密之后的握手消息发送给Server5. Server收到消息之后1234a: 收到enc_pre_master之后，会通过私钥进行解密（非对称加密算法）得到pre_masterb: 通过pre_masrer、Random_C、Random_S计算得到协商密码 enc_keyc: 通过enc_key解密握手信息，验证HASH是否和客户端发来的一致d: 生成握手信息同样适用enc_key和约定好的加密算法 6. Server发送握手信息给Client,也就是说Server验证通过了Client,并再次发送消息给Client让其验证自己7. 客户端拿到握手信息解密，握手结束。客户端解密并计算握手消息的HASH，如果与服务端发来的HASH一致，此时握手过程结束。8. 正常加密通信，握手成功之后，所有的通信数据将由之前协商密钥enc_key及约定好的算法进行加密解密。其中Https使用到的加密算法如下： 非对称加密算法：RSA，DSA/DSS 对称加密算法：AES，RC4，3DES HASH算法：MD5，SHA1，SHA256 2.2.2、 Charles抓取Https原理Charles本身就是一个协议代理工具，在上篇的Https原理上，客户端和服务器的所有通信都被Charles捕获到。如下图： 主要步骤如下： 1. Charles捕获Client发送给Server请求，并伪装成客户端向服务器发起握手请求2. 服务器响应，Charles获取到服务器的CA证书，并用根证书公钥进行解密，获取到服务器的CA证书公钥。然后Charles伪造自己的CA证书，伪装为服务器的CA证书发送给客户端3. 客户端收到返回之后，和上面讲到的过程一样，证书校验、生成密码、并使用Charles伪装的证书公钥进行加密，并生成 Https通信的协商密码enc_key4. Charles捕获到Client发来的重要信息，并使用自己伪造的证书私钥将密文解密，获取到enc_key.然后Charles使用服务器之前返回的证书公钥对明文进行加密并发送给服务器5. 去之前一样，服务器收到消息之后，用私钥解开并建立信任，然后发送加密的握手信息。6. Charles截获服务器发来的握手密文，并用对称密钥解开，再用自己伪造证书的私钥加密传给客户端7. 客户端拿到加密信息后，用公钥解开，验证HASH。握手过程正式完成，客户端与服务器端就这样建立了”信任“。 其实在整个过程中，最重要的就是enc_key,由于Charles从一开始伪造并获取了enc_key，所以在整个通信过程中Charles充当第三者，所有信息对其来讲都是透明的。 其次就是根证书，这是https一个信任链的开始。这也是Charles伪造的CA证书能获得双方信任的关键。 2.2.3、演示Charles抓取Https 原理清楚之后，其实操作就很简单了，操作的核心点就是根证书。 安装根证书（Charles Root Certificate） 让系统信任该证书 接下来将需要抓的Https链接加入到CharlesSSL代理规则中，443是Https的默认端口当然你也可以像我最后一条一样，使用 *:443 来抓取所有https的包。 通过浏览器访问自己要抓的链接，这样所有的Https都可以像Http一样明文展示都我们面前。 第三、手机抓包 手机抓包的原理其实也很简单，让手机和抓包工具处于同一局域网，并将手机的WifiProxy手动代理到电脑的Ip和Charles设置的抓包端口上，具体操作可在网上找到,具体见http://blog.csdn.net/richer1997/article/details/52198024 我这边主要讲一下手机端Https包的抓取，其实和浏览器的抓取一样： 首先需要安装Charles的根证书到手机上。 点击之后，会弹出让你在手机上配置代理到对应Ip和端口，之后通过手机浏览器打开chls.pro/ssl使用手机访问该链接之后，会自动被识别为证书，并跳转到：(当然我这里已经是安装过的，未安装的点击右上角安装即可) 之后就类似与PC端抓Https包原理一样，手机端的证书被作为根证书使用，并通过Charles拿到enc_key.将所有通信过程透明化。 第四、Charles的附加功能 在我刚开始使用Charles的时候，我只是用来简单的抓抓接口，直到我看到别人使用BurpSuite自定义请求数据并Repeat的时候，我在考虑Charles是否也有这种功能。当然不出我所料，Charles也是支持的。 在对应接口上点击右键，出现菜单，其中我经常使用到的就是Compose、Repeat和RepeatAdvanced Compose:可直接自定义对应的请求，并执行该请求。这个对我们抓包用处很大。我们可以从中得到该接口的必填参数等等的。Repeat：很简单就是执行一次重复请求操作Repeat Advanved：重复请求的高级操作，可自定义重复的次数、每隔多少秒执行。这个功能对于我们的接口的压测是很有用的。除了这几个我常用的功能，当然Charles还有更多更加实用的功能，如过滤、排序等等。还需要大家去自行使用，发现更多更好、并适用于自己的功能。小结 抓包的用处其实很大，有时候可以用来调试我们的接口、有时候也可以用来做一些对工作有益的事，当然并”不建议”用来攻击别人的网络。]]></content>
      <categories>
        <category>Python新手引导</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Charles破解教程，适用于所有版本]]></title>
    <url>%2F2017%2F07%2F03%2Fcharles_break%2F</url>
    <content type="text"><![CDATA[Charles 注册码1. Windows 用户RegName: ANONYMOUS@chinapyg.comReg_Key: 5fae99ec65736945ba官方下载后可直接激活。神key. 2. Mac 用户方式一如果不行，方式二绝对可以。 1. 方式一账号：WaitsUn.com密码：vapg-fold-dreg-inky 2. 方式二先安装Charles，然后在终端中执行下面的命令即可实现破解。 1234567891011121314charles=/Applications/Charles.app/Contents/Java/charles.jardir=charleshackmkdir $dircd $dircat &gt;&gt; License.java &lt;&lt;EOFpackage com.xk72.charles;public final class License &#123; public static boolean a() &#123; return true; &#125; public static String b() &#123; return &quot;http://www.gfzj.us&quot;; &#125; public static String a(String name, String key) &#123; return null; &#125;&#125;EOFjavac -encoding UTF-8 License.java -d .&amp;&amp; jar -uvf $charles com/xk72/charles/License.classcd .. &amp;&amp; rm -rf $dir]]></content>
      <categories>
        <category>技术</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Github系列教程一 开门]]></title>
    <url>%2F2017%2F07%2F03%2FGithub%E7%B3%BB%E5%88%97%E6%95%99%E7%A8%8B%E4%B8%80%20%E5%BC%80%E9%97%A8%2F</url>
    <content type="text"><![CDATA[这是一套Github的小白教程 本文来自我的公众号：DeveloperPython对于Github,我相信很多人都不陌生，并且我也一直认为Github是程序员的必备，当然还有一个 StackOverFlow。 但是在我周围、包括公号里面的读者，大部分都不怎么使用Github。 因为上次我的项目被点赞到Github Trending之后（全球开源项目的热门），我发现很多点赞的国内开发者都是不怎么使用Github的。因为几乎看不到他们的代码提交记录，然而里面很多国外开发者的点赞，我再进入他们的主页，大部分开发者都是持续提交代码中。 之后我也收到好多消息，希望我写一篇关于Github的教程或者如何上Trending。 其实，我接触Github时间挺早的了，大概在上大学开始写代码的时候，就已经使用上了 Github。当时我也是只下载，不用的那种。大概在接触 Github 一年左右之后，我就开始深入使用。 到目前为止，自己 Github 中的项目已经有了130多个。 https://www.github.com/xiyouMc/ Github是一个开源、开放、免费的平台，它更多的是提供给我们学习和贡献的。 所以我决定写一个系列来讲解如何去更好的使用Github，为了让国内的开发者能合理的使用Github。 01、什么是 GithubGithub其实是一家公司，坐落在旧金山。是由三个知名的开发者在08年创办的，具体是谁就不用讲了，讲了也记不住。 这是它的 Logo: 大概也就在08年4月多，正式上线。 https://www.github.com/ 简单的来讲，Github是一个基于 Git 的版本托管平台。 大概在13年的时候，Github 用户数量已经破300万，到目前为止我想也应该上千万了吧。 因此它有一个很洋气的名字就是全球最大同性交友平台。GayHub。 02、Github、Gitlab 和 Git 的区别这个问题，我相信很多人都分不清。 有的人会把Git理解成Github。你会经常听到有人跟你讲：“你可以去Git上找下，看看有没有你想要的代码”。 如果这句话，是别人跟我讲的，那我绝对是一脸懵逼的。 至于为什么，那么我就来详细讲下这三个的区别。 先说下Git Git是一款免费、开源的分布式版本控制系统，他是由著名的Linux发明者 Linus Torvalds 开发的。 所以说Git是一个版本的控制系统，而非一个平台。 提到这个版本控制系统，大家可能会想到SVN，毕竟这是很多大学都让学生使用的东西。只不过Git是新时代的产物。 如果在15年的时候，你告诉我你们在使用SVN，那么还情有可原。毕竟那时候很多大公司还在用SVN，比如支付宝。但到现在了，你还在使用SVN那么真的是太落伍了。 所以不管是学习Github，或者从事编程行业，Git绝对算是必备技能。 接下来说Github 上面已经说过，Github 是基于Git的版本托管服务。所以Git对于Github来讲就是一个版本管理的工具。 其次Github，还有更多的功能，毕竟它是一个平台。后面的文章中，我也会列举出重要的几个。 最后来讲讲Gitlab 这个东西呢，其实是企业内部的Github。 因为Github毕竟是一个开源的、全球性的代码托管平台。 对于企业来讲，他们更希望内部有个这样类似的Git代码托管服务。所以他们会选择Gitlab，这个开源的代码托管平台。 而且Gitlab一直在更新版本，目前已经到了9.1版本。 https://github.com/gitlabhq/gitlabhq/ 从地址来看，你也会发现Gitlab是Github平台上的一个开源项目，这样也就不难理解这两个的区别了。 03、Github 的影响力我可以这么说吧，只要你能想到的大公司，他们都会在Github上有一个组织来贡献内部的优秀代码和框架。 比如：Google: https://www.gihutb.com/googleApple: https://www.github.com/apple/Facebook: https://www.github.com/facebook/Alibaba: https://www.github.com/alibaba….还有全球顶级的项目，也同样在Github。Linux: https://www.github.com/torvalds/linuxNodejs: https://www.github.com/nodejs/nodeWeex: https://github.com/alibaba/weex等等的….同样还有全球顶尖级的开发者。Linux之父 Linus:Android 之神 Jake:等等的，我就不一一列举了。 只要是在编程届厉害的人物，都会出现在Github。 并且很多牛逼的项目做开源，比如你某天听说了某个公司的xx框架开源了。那么它们绝对在Github上开源的。 因此，Github已经是开源的代名词。 04、Github能做什么 优秀的开源项目 学好使用优秀的开源项目，是一个可以避免你在软件开发中重复造轮子的事情。 确切的来讲，正是因为有个Github上优秀的开源项目，才促使了我们在软件开发中变得越来越容易、越来越快速。 比如说：网络请求库、图片加载库。如果让你去自己实现，那么时间和资源是一个很大的成本。对于大公司，可能在人力和资源上是充沛的。但是对于大部分互联网来讲时间就是一切。 所以在使用开源项目的同时，学习他们优秀的设计思想和实现方式，无疑是提升自我编程能力的好时机。 同样的，如果你能拥有一个优秀的开源项目，那么绝对是一个很好的体验。 比如说我开源的WebHubBot，当你看到自己的项目每天每时都有人在点赞，那种感觉真心是比朋友圈被点赞爽很多倍的！！！ 多人协作其实多人协作对于Github来讲无疑是一个转折点。 因为一个好的项目，绝非几个人就能搞定的，因此Github提供了很好的协作平台。 当你把代码提交上去之后，你可以让其他人和你一同开发，或者说如果你的项目很好，全球的开发者都会给你的项目做贡献。 以我为例，前段时间提交了一个很有意思的项目，之后就收到了好几个全球开发者代码贡献，如下： 因此，多人协作真心是一个很爽、很棒的功能。 其次就是搭建个人网站 Github Pages是Github提供的一套完整的博客搭建环境。 平时你会发现很多人的个人博客域名都是xxxx.github.io。这就是使用Github Pages来搭建的。使用方法很简单，也绝对是一个装逼利器。 个人简历 活跃的Github账号，是一个很好的个人简历。 据我所知，目前很多猎头和公司的HR都很喜欢逛Github。 并且很多国外的科技公司也都会通过Github来寻找优秀的人才。 所以多用Github，会让你收到很多意外的惊喜。 05、加入Github相信大家读到这里，都迫不及待的想去使用Github了。 那么事不宜迟，从现在开始，快去注册一个Github账号。 链接： https://www.github.com/ 。 注册完成之后，先玩着，了解下整个平台的功能。 同时也可以试着搜索下我的Github：ID：xiyouMchttps://www.github.com/xiyouMc 接下来，我还会继续连载Github一系列的文章。 保证你们看完之后，会有不一样的收获。 同时如果你目前在使用Git或者Github中，那么有问题的话，也同样可以给我留言，我会一一给你们解答。 ——扫描二维码，关注公众号 生活不止眼前的苟且，还有手下的代码、和嘴上的扯淡——个人博客: http://xiyoumc.0x2048.com/Github:https://www.github.com/xiyouMc]]></content>
      <categories>
        <category>Github</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Github系列教程二 「加入Github」]]></title>
    <url>%2F2017%2F07%2F03%2FGithub%E7%B3%BB%E5%88%97%E6%95%99%E7%A8%8B%E4%BA%8C%20%E5%8A%A0%E5%85%A5Github%2F</url>
    <content type="text"><![CDATA[本文同步在我的公众号: DeveloperPython相信昨天大家看过 Github系列教程一 「开门」之后，已经对Github的简介和发展史有了一个详细的了解。 那么多的不说，我继续更新。 为了更好的使用Github，第一步去了解这个平台是重要的。 因此这篇我将针对Github平台进行一个全面的讲解。 1、注册Github账号访问 https://github.com/官网。 首页就是一个注册Github的入口。 这里就很简单了，填写你的用户名、邮箱和密码。 不过提醒下，这个用户名比较重要，这相当于是你在Github的ID。 上一篇文章讲过Github可以搭建个人博客username.github.io。那么这个用户名就会在这里用到。 所以建议填写一个代表自己的ID。 比如我的xiyouMc，博客就是xiyouMc.github.io。 2、Github主面板注册完成之后，就来到了Github的主面板。 如果你是新注册的，那么不会像我这么丰富，不过玩上一段时间也就差不多类似了。 以下，我针对主要的两点进行讲解： Github的工具栏 1、Logo左上角这个Logo在Github每个页面都有，同时也是可以点击的。 当你在Github里面打开了很多页面，然后想快速回到这个面板。直接点击左上角的Logo即可。 2、搜索项目的入口这里可以输入关键字，去搜索自己想要的项目。 3、Pull requests(PR)一个可查看自己贡献代码给其他人项目的面板。 关于pr的含义，就是当自己针对别人的开源项目做了改动之后，就可以将这些改动pull requests 到对应开源者的项目中。 4、Issues这个你可以理解为Github上的聊天功能。 用这个功能你可以很方便的给别人的项目提建议或者提Bug。同时你们也可以在里面进行沟通。 5、Gist如果你没有自己的开源项目，但是你有很不错的代码片段。就可以在Gist里面将自己优秀的代码片段进行提交。 当然，你可以在Gist里面学习别人优秀的代码片段.动态栏 这里是你关注人的动态列表和你自己项目的状态记录。所以在Github上多关注一些大牛，你会看到他们的动态，包括他们点赞的项目和创建的项目。这些项目也绝对是有水平的。 3、Github个人主页点击右上角的头像，会弹出下拉列表，在里面点击 Your profile。进来之后，就进入了个人的主页。你会看到我的简介里面养了条狗。其中，几个重要的功能，我也都在上面标注出来了。 4、修改个人标签同样的，参考上面 Your profile。在那个下拉列表中，会有一个Settings，点击之后就会来到个人设置页面。这里面的内容，也都很清楚了。比如修改头像、修改用户名、简介等等的。 不过到这里，我就讲个课外话。 很多人都说Github是免费的，那他们怎么赢利的呢? 我可以很明确的告诉你，Github有付费功能，而且有点贵。 它的付费功能其实也很简单，就是一个创建私有仓库的权限。如果你买了的话，就可以创建私有的项目，当然私有的意思就是别人无法看到你的代码。 具体价格，每个月大概7刀，折合人民币就是42块钱左右。所以如果不是非必须使用私有，还是建议别买这个。 5、创建项目点击 New repository，就进入了创建项目的页面。填写你的项目名字、加上一句高大上的简介，选择Public，然后点击Create repository。就走出了开源的第一步。 创建之后的项目面板大概是这样的：因为这是一个已经成型的项目，所以说，如果你们是刚创建的一个项目，那么不会有这么丰富的内容。最多里面也就一个项目的说明文档Readme.md。当然这是需要使用 Markdown语法的，简称md,也同样是程序员必备的技能。 6、总结其实这篇文章写得相对简单点，如果你是一个已经使用Github一段时间的可能帮助不大。但是如果你刚接触或者没接触过Github，我相信这些基础知识对于你来讲还是有很大意义的。 所以走出你的开源第一步，勇敢的将自己的项目提交到Github吧。 扫描二维码，关注公众号 生活不止眼前的苟且，还有手下的代码、和嘴上的扯淡—— 个人博客: http://xiyoumc.0x2048.com/ Github:https://www.github.com/xiyouMc]]></content>
      <categories>
        <category>Github</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Google Hacking --你真的会用Google吗？]]></title>
    <url>%2F2017%2F07%2F03%2FGoogle%20Hacking%20--%E4%BD%A0%E7%9C%9F%E7%9A%84%E4%BC%9A%E7%94%A8Google%E5%90%97%EF%BC%9F%2F</url>
    <content type="text"><![CDATA[你真的会用Google吗？Google Hacking提升工作效率 阅读本文需要6.66分钟 Google hacking，也叫作google dorking。如果在 Google 上搜索 GoogleHack,你会发现很多文章都是零几年的。所以已经不是陌生词了。 简介 语法 具体应用和示例 0x00. 简介 GoogleHack,旨在使用Google搜索引擎或者其他Google应用程序通过特定语法来查找网站配置或代码中的安全漏洞。 0x01. 语法 基本语法: operator:search_term 其中以 all 开头的操作符在一般情况下一个查询中只能使用一次，不能与其他操作符混用. intext: 可以指定网页内容中的关键字作为搜索条件,并且冒号后面只能跟一个关键词。如 Google 搜索： intext:爬虫 那么将返回所有包含 “爬虫” 的网页,同时也可以与其他操作符混用。 allintext: 类似于 intext: ，能接多个关键词，不可以与其他操作符混用。 intitle: 搜索标题中包含关键字的网页。如 Google搜索: intitle:DeveloperPython,那么搜索出来的将都是标题中包含 DeveloperPython的网页。 allintitle: 同 intitle:,可接多个关键字，但不能和其他其他操作符混用。 cache: 输入URL，搜索特定网页的缓存快照，即使页面发生了变动甚至不存在了，依然能看到它的副本。 define: 搜索关键词的定义来源。如 Google搜索: define:java，那么将返回关于python的定义，不能与其他操作符混用 filetype: 搜索指定类型的文件。 如 Google搜索： filetype:txt，那么将返回以 txt 结尾的文件URL，可以与其他操作符混用. ext: 同filetype info: 搜索到指定URL的摘要信息和其他相关信息,如 Google搜索： info:facebook.com，就会放回facebook的相关信息。不能与其他操作符混用。 inurl: 搜索URL中包含指定关键字的网站。一般与site联合指定来找后台、管理等之类的页面，可以与其他操作符混用。 allinurl: 同 inurl:,可接多个关键字。不能与其他操作符混用。 link: 可搜索到链接到该URL的页面。如 Google搜索: link:www.xiyoumobile.com ，就会返回所有链接到该网站的页面。 site: 可以指定网站、域或者子域，将搜索范围缩小。 related: 搜索与该URL相关的页面。 如 Google搜索： ‘related:www.baidu.com’ inanchor: 搜索一个HTML标记中的一个链接的文本表现形式。即在链接文本中搜索冒号后面紧接的一个关键词。 至于“链接文本”，比如 &lt;a href=&quot;GNU/Linuxhttp://www.linux.org/&quot;&gt;GNU/Linux&lt;/a&gt; 以上代码中的“GNU/Linux”就是链接文本 stocks: 搜索指定公司的股票市场信息 0x03. 具体应用和示例A.基础网站爬取（site:）site:旨在将搜索范围缩小到指定的网站、域或子域，如下： site:facebook.com 一般我们剔除一些无意义的干扰网站，这时候就需要使用到 负搜索. site:facebook.com -site:www.facebook.com 在这里我推荐一个终端浏览器 lynx ，玩Linux的应该很清楚这个。 关于 lynx 的简介，这里有篇文章: http://linux.ximizi.com/linux/linux3298.htm 如下，可通过 lynx 来代替我们手动在Google搜索引擎中做的操作： dump这些操作符的结果 然后我们通过正则拿到我们想要的链接: B. 端口扫描 可使用 inurl:结合 ‘intext:’ 如下： 这里分享一个端口扫描的工具 Network Query Tool 简称 nqt. 我们通过 GoogleHack 来找到这个工具: 打开第一个: 0x04. 总结如上面例子，我们正确的使用Google，不仅能帮我们快速找到所需要的文章、电影、各种种子、*V等等的，并且还能针对我们的渗透测试省时省力。]]></content>
      <categories>
        <category>Python新手引导</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Hybrid调试指南]]></title>
    <url>%2F2017%2F07%2F03%2Fhybrid%E8%B0%83%E8%AF%95%E6%8C%87%E5%8D%97%2F</url>
    <content type="text"><![CDATA[Hybrid调试指南 开发接口过程中如何自测接口? Dependency Chrome Android SDK Level &gt;=19 Usage Android设备连接电脑，并打开USB调试 通过Hybrid打开任意页面 使用Chrome浏览器打开，chrome://inspect, 调用JSBridge对应的接口 Picture 以下是 “隐藏TitleBar”为例，通过JSBridge来隐藏Native的标题栏 打开Console控制台 注入JSBridge.call(“hideTitlebar”); App端隐藏掉Titlebar 通过Hybrid打开任意页面，测试页面-Slideplus素材中心页 使用Chrome浏览器打开，chrome://inspect Sample&gt; JSBridge.call(“hideTitlebar”) —Hide Title bar]]></content>
      <categories>
        <category>Hybrid</category>
      </categories>
      <tags>
        <tag>Hybrid</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2016年度总结]]></title>
    <url>%2F2017%2F07%2F03%2F2016%E5%B9%B4%E5%BA%A6%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[2016年度总结 2016年很快，离上次写总结已经一年了。平时文档倒是写的不少，但是真正要总结起来自己，确实有点说不出口，那么就简单的总结下。从事业、生活等。 事业 事业即我的技术，从刚进入职场，就开始做框架上的东西，现在想来这也是一个很不错的开始。因为少了业务的繁杂，多了技术的沉淀和技术的优化—Hybrid。Hybrid是一个混合式开发的技术，通过JSBridge来桥接H5和Native。这个框架着实是影响到了我之后的发展规划。在开发这个系统的过程中，学习到了很多： JS和H5当然是第一个学习到的东西，这两个技术一直是我在学生时期想要学习的但是一直没有沉下心来学习。 Module间的依赖关系，一年半左右的Hybrid开发，也确实是让我积累了很多关于模块依赖、接口开发等等的技术，并一步步提升自己的开发效率。 整个App的插件化开发，在开发Hybrid的同时我经常会去问框架同学问题，问他们关于App插件化、动态注入、懒加载等等的技术，这也是为自己后面开发插件化框架打下了基础。 插件化框架，去年中旬花了一段时间去研究ClassLoader，遇到了很多坑，也一一进行了填补,虽然不是一个多么牛逼的框架，但是确实是让我学习到了很多。当然现在也是开源在我的Github，Apk插件化开发 接触业务，去年下半年一直在开发业务中，一个从零开始的业务，这也算是将自己沉淀的技术进行一次应用的过程，业务有时候根本不是取决于你的技术，而是取决于各种因素，如果你是程序员你会懂得。 16年我也花了很多时间在Github上，每天必看Trending. Java、JS、Html等等的技术。16年也认识了很多业内的大神。 2017年将转型Growth Hacker，致力于公司的数据增长，将会放下Android的重心，当然Android还依然是我的一个长处。 生活 对我而言，技术的产出永远都是生活质量的提升。有时候我在想:”如果能让我开心、很爽的开发自己喜欢的技术，那么金钱对我来说都是多余的”这个想法是多么幼稚.下半年一直在考虑房子的问题，看了周围一大圈，发现全都是16年9 10月份上涨之后的情况，当然貌似也是G20导致的。据周围人的看法，17年将不会有很大的变动，所以在年后将会去进一步了解并决定。 这也是我去年搬家的时候对17年立的flag。希望会实现。16年成长了很多，也学会了如何去承担一份感情。褪去了过去的幼稚，重新认识自己，看清自己，并去选择对方。一起走下去。 有意思的东西 上个周末，花了一点时间将之前自己的一个老应用接入了支付模块，这个系统一直以来都是免费提供给母校的学生使用的，但是慢慢的失去了很多开发的动力，因此我决定花点时间将盈利加进去，刚更新那几天，每天100左右的收入是有的，当然我并没有多在乎一天能多钱。只是为了增加自己平时空闲时间去开发的动力。当然后面还是降了下来，也让我意识到运营的重要性。之前自己一直都是扮演产品和开发的角色，后面增加支付，又得扮演运营的角色，最后还是证明的我不是做运营的料。 2017 2017年，也不说是新的开始了，因为有很多事情要一直做下去。 这一年，我会花更多的时间在开源方面、自身技术的深度沉淀和公司的数据增长上，并继续向周围技术进行扩散。 买房、买车。。。。 那么是否考虑结婚呢。。。]]></content>
      <categories>
        <category>总结</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[小程序之Github开源社区]]></title>
    <url>%2F2017%2F07%2F03%2FGithubTrending%2F</url>
    <content type="text"><![CDATA[01、初衷大概上上周我花了周末两天的时间编写了一款小程序并顺利提交审核。 也就在前两天我的小程序 「Github开源社区」 历经了两周的审核，终于。。。。。。成功发布了，并且绑定到了公众号。 以下是这两天时间的数据分析报表。 （实时访问次数 pv） 粗略的分析下：实时访问次数波动很明显，当然这也是正常的。高流量基本保持在早上十点到中午。晚上还会出现个别熬夜的程序员在看代码。总体呈下降趋势。 (访问来源、访问时长、访问深度) 粗略的分析下： 访问来源主要来自会话，其次来自扫小程序码。 访问时长最高点在 11-20 秒，当然还有大量用户超过1分多钟在使用小程序。 其次，访问深度（访问了多少个页面），大部分只访问了一个页面，最深页面在5个页面的深度。 ——————划重点———– 那么，为什么我会选择去编写一个关于 程序员 的小程序呢？ 首先，我是程序员。其次，也是因为前段时间我一直在更新关于Github的教程。因此，为了方便自己，同时方便读者和开发者，我选择开发了一款关于Github的小程序。 02、小程序的功能「Github开源社区」目前的功能很简单，包括每日开源趋势、模糊搜索想要的代码、查看具体的代码文档以及仓库的信息。 用微信扫一扫下方，可体验小程序。 效果图(启动小程序，默认展示当天最热开源项目,并支持查看文档) (支持搜索代码) 后续将支持的功能 代码查看登录Github账号，实现点赞等社区。。。 03、开发过程虽说这是一款工具性的小程序，但确切的说是一款C/S的软件。C端也就是集成进微信的小程序，S端的话就是我编写并部署在阿里云的服务端。 C端包含了wxml、wxss、json、js还有其他配置属性。 S端的话我就直接用Python + web.py构建的，同时基于Github Api开发。 开发流程看似简单，但对于我这个前端半调子来讲，确实在开发C端遇到很多问题。当然，解决方法也就是Google + 大神。 04、如何开发一款自己的小程序一个idea 这个idea很重要，因为自己的想法将会推动自己去实践并完成。如果没有一个自己的idea，那么与其说学技术，倒不如说你是在说服自己拥有多一点的技能。 所以，idea很重要。 如果一开始我并没有想好要去做什么小程序，然后就上手去学习如何开发，我猜可能在后面的学习过程中我将会很难坚持。因为那样是枯燥无味的，我并不知道自己用这个技术能做点什么。 其次，Github开源社区的idea我在开发前一个礼拜都有了。外加晚上熬夜到一两点，加上周末，大概花了两三天时间就出来了。 所以，在学习开发小程序之前，先想好自己要做什么。接下来，再动手去了解、学习这个技术，并运用起来。 需要了解的技术点 虽说小程序有一套自己的开发语言，但是，框架中主要的还是Page的生命周期和App的管理。其次，就是css的一些知识点。 所以，一开始你可以去小程序的官网着重了解Page生命周期和App的管理。其次，熟悉下小程序的那几个重要的组件，其中包括View、button等等的。 官网：https://mp.weixin.qq.com/debug/wxadoc/dev/component/ 接下来，你需要学习css的东西，这个其实不复杂，去w3c上面将css的关键知识点过一遍。了解前端的页面是如何布局的。 上手 IDE搭建微信团队针对小程序专门出了一款开发工具。这里我直接上链接:https://mp.weixin.qq.com/debug/wxadoc/dev/devtools/download.html 项目结构 1234567js ---------- JavaScript文件json -------- 项目配置文件，负责窗口颜色等等wxml ------- 类似HTML文件wxss ------- 类似CSS文件 在根目录通过App来命名这四种文件，也就是程序的入口。App.js 这个文件是必须要有的。其中主要写的内容也就是上面提到过管理App生命周期的。App.json 这个也是必须要有的。其中包含了整个小程序的全局配置。App.wxss 有点类似于css的，进行布局用的。当然，这也是全局的。App.wxml 这个可选，是用来布局小程序的界面的。有点类似于html。关于具体的文档，链接在这。https://mp.weixin.qq.com/debug/wxadoc/dev/component/如果有需要详细的讲解，那么可以留言，我考虑后续更新一系列的小程序开发教程。 05、个人开发经验虽说在不早之前，微信开放了个人小程序的开发资格。不过，你还是不能随心所欲的开发小程序。 你能随心所欲开发的功能也大概只有工具类的。假设，你要是想开发一个社区类的小程序，那么你得要有诸多的证件。所以，在上手小程序之前，你需要看看小程序的开发规约，确保自己的idea是否需要各种证件。 其次，小程序的兼容性，目前Github开源社区在 iOS 9.3.2 上出现 SDK Exception 。还没找到合理的解决方案。 审核时间较长。你能做的就是等待。 开发工具有时候响应很慢，同样的你只有等待，毕竟目前开发工具并没有到1.0版本。 等等的坑。。。 目前动态化的开发模式越来越火了，包括JSBridge、Weex、React等等的。所以，作为非前端的你是否也需要学习下前端的知识点呢？ 来自公众号 : DeveloperPython 行为艺术要持之以恒，iOS专用赞赏通道。]]></content>
      <categories>
        <category>小程序</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[2000个Star的Github项目很牛逼？]]></title>
    <url>%2F2017%2F07%2F03%2F2000%E4%B8%AAStar%E7%9A%84Github%E9%A1%B9%E7%9B%AE%E5%BE%88%E7%89%9B%E9%80%BC%EF%BC%9F%2F</url>
    <content type="text"><![CDATA[首先，说明下，这篇文章是基于我的开源项目WebHubBot来讲的。不清楚的可以看XiyouMc/WebHubBot。 这篇文章，其实我很早都想写了。也算是对整个项目的总结，其次也是给那些问WebHubBot技术的人一个答复。 说实话，这个项目的技术很普通。普通到什么程度呢？我可以很清楚的告诉你，这个项目就用了屈指可数的几个技术点：Http协议、Html、Python、MongoDB 和 Scrapy。就这么几个技术，对于一般的程序员来讲，真心不是什么牛逼点。 那么接下来，我主要从为什么会火和具体的技术点来扯下。 1、为什么这个项目会火呢？在我看来，它能火起来真的是运气。 如果真的要我说出个所以然，那么我觉得就因为这两点它才会火起来。 第一点，因为项目爬的网站是有诱惑力的。 其实，大家可以在Github上搜索下此类网站的爬虫。你会搜索到很多类似的爬虫。但是他们的Star反而都是几十个，甚至没有。 第二点，我有一份精简、清晰的英文文档。 其中，我很清晰的从项目简介、项目环境、启动前配置、启动方式、截图、数据库说明等的这几个方面进行简单描述。而且我觉得这些就够了。 最重要的一点，就是这篇英文文档写的很简单，都是简单词汇。 2、牛逼的技术？其实，在这个社会，同一个行业并没有牛逼一说，反而牛逼的是不同行业的。就比如，会造飞机的就是牛逼。所以，这个项目的技术点在整个互联网的圈子并没有牛逼到哪去。 为什么这么说呢 ？ Http协议 一套应用层的协议，官话是超文本传输协议。为什么提这个呢，是因为要去爬一个网站，你首先需要弄清楚，在什么样的请求下才能响应正常、又是怎么拿到网页数据的。这样，你才有去写爬虫请求的能力。 我这里推荐一个学习的地址：http://www.cnblogs.com/ranyonsue/p/5984001.html Html页面 写爬虫不需要你有多么牛逼的前端经验。就像我，从未写过前端页面，但是前端那些标签，我几乎都能看懂。 不过对于爬虫来讲，可能Xpath语法的会重要一点。Xpath是什么呢？Xpath是XML路径语言。它是为了确定XML文档中某部分位置的语言。众所周知，Html其中也是使用XML语言。因此，简单的来说，我们可以通过Xpath来定位到Html页面中某个控件的位置。 比如，就Baidu.com的首页来讲，我们通过Xpath来拿到 “百度一下” 按钮的位置。 那么， “百度一下” 的XPath路径将是 //input[@class=”bg s_btn”] ，这个路径也就会定位到这个控件的位置。 接下来就简单了，我们可以拿到这个控件之后去做Click操作。这样的话，就用代码完成了百度一下的功能。 同样的，推荐教程附上：http://www.w3school.com.cn/xpath/index.asp Python + Scrapy Python算是爬虫中的利器了，如果你不会Python。那么其他语言同样可以实现爬虫。但是，工作量将是Python的n倍。 Python更适合做爬虫。之所以这么讲，是因为它的框架很多，开放的依赖库很多，其次就是工作效率高，Java要用100行来实现的一个小工具，Python也许只要10行。就是这么牛逼。所以，你不上手更待何时。 这里，送上我的福利，PythonDev小密圈，适合老司机更适合新手。 其次，Scrapy框架。这个框架呢，其实很难评价。因为你要是用不好的话，会出现杀鸡焉用牛刀的笑话。 Scrapy是一套及其灵活的框架。为什么说它灵活呢？ 首先它的parse -&gt; yield item -&gt; pipeline流程已经是所有爬虫的固有模式，其中解析函数可以自己来实现，怎么处理网页自己决定。pipeline可以自己写，爬到的数据怎么处理也是自己可以决定的。 其次，就是底层操作的修改，包括代理中间件、下载中间件之类的，这些也都可以通过middleware来实现。甚至，目前已经有很多开源的中间件已经实现绝大部分的爬虫需求。 奉上Scrapy教程:http://scrapy-chs.readthedocs.io/zh_CN/0.24/intro/tutorial.html 最后，来简单的说一个针对新手的爬虫框架，Beautiful Soup。这个，我也没接触过。但是，我知道它是真的很简单。首先，它不需要多少代码就可以写出一个完整的爬虫应用程序；其次，是因为我家属，做Android的司机，第一次玩BS也是非常快的就上手了。 所以，Beautiful Soup，这个框架绝对是新手必备的。 MongoDB 持久化、非关系型数据库。多用于分布式系统。 之所以，WebHubBot会选择用MongoDB。重要的一点是Python可以直接将对象转化为JSON，并且pymongo可以直接将JSON数据插入到MongoDB，这不是很方便嘛，且减少了我来写SQL的很多时间，何乐而不为呢。 当然，MongoDB存储数据的格式不是JSON，而是一个非常类似于JSON的BSON数据。 其次，Python中使用到的是pymongo。使用pip安装下就好了。 同时MongoDB的安装方式和教程，也很简单。 教程链接：http://www.runoob.com/mongodb/mongodb-tutorial.html 最后推荐几个MongoDB的可视化工具。RoboMongo : https://robomongo.org/Toad：http://www.toadworld.com/products/toad-for-oracle 第一个，Windows系统多数使用。第二，Mac多数。Linux的大神，就用命令好了。 3、总结项目中的技术点其实都是基础。我并没有资格说这个项目有多牛逼。在我看来，它就是基础知识堆积起来的而已。 所以，学好基础才是王道，其次要把技术玩起来。 努力成为一个有想法的全栈工程师。 长摁‘识别二维码’，一起进步 生活不止眼前的苟且，还有手下的代码、 和嘴上的扯淡——个人博客: http://xiyoumc.0x2048.com/ Github:https://www.github.com/xiyouMc 点击 Join，加入Python技术成长圈子，我在这里等着你。]]></content>
      <categories>
        <category>Python新手引导</category>
      </categories>
  </entry>
</search>